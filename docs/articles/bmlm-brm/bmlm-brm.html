<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience • bmlm</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/sandstone/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">bmlm</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../articles/index.html">Articles</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mvuorre/bmlm/">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience</h1>
                        <h4 class="author">Matti Vuorre</h4>
            
            <h4 class="date">2017-09-25</h4>
          </div>

    
    
<div class="contents">
<div id="abstract" class="section level1">
<h1 class="hasAnchor">
<a href="#abstract" class="anchor"></a>Abstract</h1>
<p>Statistical mediation allows researchers to investigate potential causal effects of experimental manipulations through intervening variables. It is a powerful tool for assessing the presence and strength of postulated causal mechanisms. Although mediation is used in certain areas of psychology, it is rarely applied in cognitive psychology and neuroscience. One reason for the scarcity of applications is that these areas of psychology commonly employ within-subjects designs, and mediation models for within-subjects data is considerably more complicated than for between-subjects data. Here, we draw attention to the importance and ubiquity of mediational hypotheses in within-subjects designs, and we present a general and flexible software package for conducting Bayesian within-subjects mediation analyses in the R programming environment. We use experimental data from cognitive psychology to illustrate the benefits of within-subject mediation for theory testing and comparison.</p>
</div>
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>Many important questions in psychology concern a causal chain of relationships between an initial cause and its effect through an intermediary process. One common method for investigating such causal models, statistical mediation, assesses to what extent the effect of an independent variable (IV) on a dependent variable (DV) is mediated by an intervening variable M. Mediation is suitable for answering many questions about causal processes in cognitive psychology and neuroscience, such as: “Do expectations alter brain activity, and thereby change how individuals respond to stimuli?” <span class="citation">(Atlas, Bolger, Lindquist, &amp; Wager, 2010)</span>; and “Does cellphone use while driving cause traffic accidents by increasing drivers’ attentional demands?” <span class="citation">(e.g. Ishigami &amp; Klein, 2009)</span>. Mediation models are valuable because they allow the evaluation of theoretical predictions about causal mechanisms, whether in testing a single theory or in theory comparison.</p>
<p>Experiments in cognitive psychology, and related areas, often investigate moderational hypotheses, by for example testing interaction effects in multi-way ANOVAs, but investigations of mediational hypotheses <span class="citation">(see Baron &amp; Kenny, 1986 for a discussion on the distinction between mediating and moderating variables)</span> in cognitive psychology are rare in comparison to many other branches of psychology <span class="citation">(Table 1 in MacKinnon, Fairchild, &amp; Fritz, 2007)</span>. One reason for the rarity of mediational hypotheses in this area may relate to the difficulties associated with appropriately analyzing mediation when the data consist of repeated measures over individuals in within-subject designs—as is often the case in cognitive experiments. One general, and increasingly common, strategy for analyzing repeated measures data and within-subject designs is multilevel modeling, which postulates that the data are nested within units, such as trial-level observations nested within individual participants. Over the past decade, multilevel analysis has been successfully implemented to assess mediation where data are repeatedly measured within individuals in different conditions, such as many experiments in cognitive psychology and neuroscience. Here, we briefly introduce the classic mediation model of Baron and Kenny <span class="citation">(1986)</span> and the multilevel modeling approach to estimating mediation with repeated measures <span class="citation">(Kenny, Kashy, &amp; Bolger, 1998; Kenny, Korchmaros, &amp; Bolger, 2003)</span>. We then introduce an easy to use software package for Bayesian estimation of multilevel mediation models in the R programming environment, and illustrate its use with an example.</p>
<div id="mediation" class="section level2">
<h2 class="hasAnchor">
<a href="#mediation" class="anchor"></a>Mediation</h2>
<p>In what follows, we discuss a mediation model where X is the hypothesized causal variable, usually the IV in an experiment, Y is the measured outcome (the DV), and M a measured variable which hypothetically mediates X’s effect on Y. We restrict our discussion to cases where X and Y are either binary or continuous and M is continuous. We focus on, and implement in the software presented below, this three variable mediation model because of its wide applicability and suitability for data from cognitive psychology and neuroscience experiments. This model is illustrated in Figure @ref(fig:template-mediation-plot).</p>
<div class="figure">
<img src="bmlm-brm_files/figure-html/template-mediation-plot-1.png" alt="Diagram of the mediation model." width="403.2"><p class="caption">
Diagram of the mediation model.
</p>
</div>
<p>The three causal paths in Figure @ref(fig:template-mediation-plot)—<em>a</em>, <em>b</em>, and <em>c’</em>, corresponding to X’s effect on M, M’s effect on Y, and X’s effect on Y having taken M into account, respectively—correspond to parameters from two regression models, one in which M is the outcome and X the predictor, and one in which Y is the outcome and X and M the simultaneous predictors. From these parameters, we can compute the mediation effect (the product <em>ab</em>; also known as the indirect effect), and the total effect of X on Y,</p>
<span class="math display">\[\begin{equation}
c = c' + ab .
\end{equation}\]</span>
<p>Thus, the total causal effect of X, which is captured by the parameter <em>c</em>, can be decomposed precisely into two components, a direct effect <em>c’</em> and an indirect effect <em>ab</em> (the product of the <em>a</em> and <em>b</em> paths). There is evidence of mediation when the uncertainty interval (we later define this interval in more detail and distinguish Confidence and Credible Intervals) for <em>ab</em> is sufficiently small that one can rule out zero as a likely population value. There is evidence of complete mediation if the uncertainty interval for the direct component <em>c’</em> is narrow around zero. As in all conclusions from data, assertions of mediation are probabilistic (and we caution users not to interpret the uncertainty intervals as hypothesis tests). Furtheremore, the distinction between complete and partial mediation may not always be useful, and researchers may instead want to focus on the magnitude of the mediation effect <span class="citation">(Shrout &amp; Bolger, 2002)</span>.</p>
<p>To continue with the cellphone and traffic accident example, talking on a cellphone (X) may increase the driver’s attentional or cognitive load (M; path <em>a</em>), which in turn may lead to traffic accidents (Y; path <em>b</em>) <span class="citation">(e.g. see Ishigami &amp; Klein, 2009)</span>. If attentional or cognitive demands completely explained the cellphone use <span class="math inline">\(\rightarrow\)</span> traffic accidents relationship, then the mediation effect (<em>ab</em>) would be close in size to <em>c</em>, whereas the direct effect (<em>c’</em>) would be close to zero. If attentional demands did not completely explain the relationship, <em>c’</em> and its associated uncertainty interval would also allow excluding zero as a plausible value. Viewed in this light, the mediation model consists of a pair of regression models, and inference is performed by interpreting the model’s estimated parameters and their transformations <span class="citation">(<em>ab</em>, <em>c’</em>, <em>c</em>; Baron &amp; Kenny, 1986; Shrout &amp; Bolger, 2002)</span>. Importantly, this logic can be extended to multilevel regression models to analyze data with repeated measures <span class="citation">(Kenny et al., 2003)</span>, a task we turn to next.</p>
</div>
<div id="multilevel-mediation-model-for-repeated-measures" class="section level2">
<h2 class="hasAnchor">
<a href="#multilevel-mediation-model-for-repeated-measures" class="anchor"></a>Multilevel mediation model for repeated measures</h2>
<p>Multilevel modeling (sometimes called hierarchical modeling, or linear mixed modeling) is a general approach for treating non-independent observations, such as repeated measures within individuals in psychological experiments. The key assumption in a multilevel model is that the lower or trial level observations are nested within upper level units (individual participants), and the general approach consists of estimating regression models where parameters at each level are estimated simultaneously. In educational research, the upper level units can be schools, and the lower level observations can be students within those schools. In cognitive experiments, the upper level units are persons, and the lower-level units are measured repeatedly over trials. Such data structures characterize many—if not most—within-subject experiments in cognitive psychology, where each subject is repeatedly exposed to each level of the treatment variable. For example, in the Stroop task <span class="citation">(Stroop, 1935)</span>, subjects usually observe (multiple instances of) both congruently and incongruently colored letters.</p>
<p>Within-subject designs and repeated measures have traditionally been analyzed with methods such as repeated measures AN(C)OVA. However, multilevel models have many benefits over these methods, such as the ability to naturally account for unbalanced data (unequal number of observations across individuals, groups, and conditions), the ability to incorporate continuous and categorical variables, estimation of the variation in effects across individuals, and the extent to which the effects covary in the population of individuals <span class="citation">(see e.g. Bolger &amp; Laurenceau, 2013; Gelman &amp; Hill, 2007; McElreath, 2016)</span>. For these and other reasons, multilevel models have grown in popularity at a rapid pace.</p>
<p>Importantly, multilevel modeling is also applicable in mediation analysis when the data consist of multiple measurements within individuals, allowing either some or all of the paths to vary between individuals in the study. As in other types of data where measurements are correlated (within-individuals, for example), ignoring this structure of the data can lead to inaccurate standard errors and thereby lead to over- or underconfidence in one’s findings. When each of the X, M, and Y variables are repeatedly measured within individuals, the mediation model is commonly known as 1 <span class="math inline">\(\rightarrow\)</span> 1 <span class="math inline">\(\rightarrow\)</span> 1, or <em>lower level mediation</em> because each variable is measured at the lowest level <span class="citation">(Kenny et al., 2003; level 1, trials, in contrast to level 2, the individuals; Krull &amp; MacKinnon, 2001; Preacher, 2015)</span>. In the current work, we focus on this model. Other multilevel mediation models include 2 <span class="math inline">\(\rightarrow\)</span> 1 <span class="math inline">\(\rightarrow\)</span> 1 mediation, where the X variable does not vary at the lower level <span class="citation">(Preacher, 2015; Raudenbush &amp; Sampson, 1999)</span>, and 2 <span class="math inline">\(\rightarrow\)</span> 2 <span class="math inline">\(\rightarrow\)</span> 1 mediation, where only the outcome variable (Y) is repeatedly measured <span class="citation">(Krull &amp; MacKinnon, 2001)</span>.</p>
<p>After the topic was introduced <span class="citation">(Kenny et al., 1998)</span>, multilevel mediation has been attracted interest both in methodology development and application <span class="citation">(Preacher, 2015)</span>. It has been succesfully applied in 1 <span class="math inline">\(\rightarrow\)</span> 1 <span class="math inline">\(\rightarrow\)</span> 1 models <span class="citation">(Kenny et al., 2003)</span>, multilevel models with moderation <span class="citation">(Bauer, Preacher, &amp; Gil, 2006)</span>, but requires care in application, such as considerations of within-cluster centering variables to isolate between- and within-subject effects from each other <span class="citation">(Zhang, Zyphur, &amp; Preacher, 2009)</span>. Multilevel mediation has also been extended to multilevel structural equation modeling <span class="citation">(Preacher, Zyphur, &amp; Zhang, 2010)</span>, but SEM approaches are outside of the scope of the current work.</p>
<div id="multilevel-mediation-equations" class="section level3">
<h3 class="hasAnchor">
<a href="#multilevel-mediation-equations" class="anchor"></a>Multilevel mediation equations</h3>
<p>In this article, we consider a mediation model applied to data where the independent variable is manipulated within individuals, and the outcome and hypothesized mediating variables are measured on each trial. These data then afford two levels of analysis: At the lower level are trial-level observations, which are clustered within individual persons at the upper level. The following equations refer to (and the software presented below requires) data sets structured in long format. That is, each observation is on a separate row, and each variable has its own column. When an experiment consists of multiple trials, then each row would represent a trial, and the different variables measured (or manipulated) during the trials would be in their own columns. The example data are presented in this format in Table @ref(tab:example1-data-table).</p>
<p>The multilevel mediation equations include both population- and subject-level parameters. The population-level parameters describe the distribution of the parameters in the population, and are usually of key interest in the analysis. The means of these distributions (sometimes known as “fixed effects”) describe the effects “for the average person” <span class="citation">(Bolger &amp; Laurenceau, 2013)</span>, whereas their standard deviations (sometimes known as “random effects”) describe the extent to which people differ from one another in the population. The subject-level parameters are specific to the individuals in the current sample of subjects, and are considered random draws from the population-level distribution. We avoid using the terms “fixed” and “random” because they can be confusing, and are less meaningful in the Bayesian context where all parameters are random in some sense <span class="citation">(Gelman &amp; Hill, 2007, p. 245; Gelman et al., 2013, p. 383)</span>.</p>
<p>We denote the subject-level effects with the same letters as the population-level effects but prepend them with <em>u</em> and append with the index variable <em>j</em> to specify that they vary across units of <em>j</em> (the individual subjects; Figure @ref(fig:template-multilevel-mediation))<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. An important addition to the equations is the covariance of the subject-level <span class="math inline">\(a_j\)</span> and <span class="math inline">\(b_j\)</span> parameters, illustrated on top of Figure @ref(fig:template-multilevel-mediation) (and explained in further detail below).</p>
<div class="figure">
<embed src="includes/multilevel-mediation.pdf"></embed><p class="caption">Diagram of the within-subjects mediation model.</p>
</div>
<p>In writing the model, we deviate from the common “error term” representation, where the stochastic component of the model is added separately to indicate that the errors are normally distributed, and instead represent the models as probability distributions themselves, an approach we think is more natural in the Bayesian context.</p>
<p>Analyzing the causal paths in Figure @ref(fig:template-multilevel-mediation) consists of estimating two multilevel regression equations. For path <em>a</em> (X’s effect on M), we model each observation of <span class="math inline">\(M_{ij}\)</span> (observation in row <em>i</em> for individual <em>j</em>; see Table 1) as a random draw from a Gaussian distribution with mean <span class="math inline">\(\mu_{M_{ij}}\)</span> and standard deviation <span class="math inline">\(\sigma_M\)</span>. Note that <span class="math inline">\(\sigma_M\)</span> is the standard deviation of the lower-level residual. The linear model is then represented as a regression equation for <span class="math inline">\(\mu_{M_{ij}}\)</span>,</p>
<span class="math display">\[\begin{equation}
M_{ij} \sim N(\mu_{M_{ij}}, \sigma_M^2)
\end{equation}\begin{equation}
\mu_{M_{ij}} = (d_M + u_{dM_j}) + (a + u_{a_j}) X_{ij}.
\end{equation}\]</span>
<p>The first term in equation 3, <span class="math inline">\(d_M\)</span>, is the population-level intercept for M, and <span class="math inline">\(u_{dM_j}\)</span> is the subject-level intercept for subject <em>j</em> (see footnote 1). The M <span class="math inline">\(\rightarrow\)</span> Y and X <span class="math inline">\(\rightarrow\)</span> Y slopes (paths <em>b</em> and <em>c’</em>) are captured by modeling <span class="math inline">\(Y_{ij}\)</span> (observation of Y in row <em>i</em> for individual <em>j</em>; see Table 1) as random draws from a Gaussian distribution with mean <span class="math inline">\(\mu_{Y_{ij}}\)</span> and standard deviation <span class="math inline">\(\sigma_Y\)</span> (which, again, is the lower-level residual of <em>Y</em>).</p>
<span class="math display">\[\begin{equation}
Y_{ij} \sim N(\mu_{Y_{ij}}, \sigma_Y^2)
\end{equation}\begin{equation}
\mu_{Y_{ij}} = (d_Y + u_{dY_j}) + (c' + u_{c'_j}) X_{ij} + (b + u_{b_j}) M_{ij}.
\end{equation}\]</span>
<p>This regression predicts Y from the combination of population-level and subject-level intercepts <span class="math inline">\(d_Y\)</span> and <span class="math inline">\(u_{dY_j}\)</span>, respectively; population and subject-level direct effects of X on Y (<span class="math inline">\(c'\)</span> and <span class="math inline">\(u_{c'_j}\)</span>); and population- and subject-level effects of M on Y (<span class="math inline">\(b\)</span> and <span class="math inline">\(u_{b_j}\)</span>).</p>
<p>The multilevel nature of this model is captured by specifying the subject-level parameters as draws from a multivariate normal distribution with a 5 x 1 vector of means of zero and a 5 x 5 covariance matrix <span class="math inline">\(\Sigma\)</span>,</p>
<span class="math display">\[\begin{equation}
\left[\begin{array}{c}
u_{dM_j} \\ u_{dY_j} \\ u_{a_j} \\ u_{b_j} \\ u_{c'_j}
\end{array}\right] 
\sim N( 0 , \Sigma) .
\end{equation}\]</span>
<p>Together, equations 2-6 constitute the multilevel mediation model. From the model’s estimated parameters, we can calculate for each individual, and the population average, all the additional parameters that are used to assess mediation, such as <em>me</em> (population-level mediation effect; also known as indirect effect) or <span class="math inline">\(u_{me_3}\)</span> (mediation effect for person 3). However, calculating the mediation effect, and therefore the total effect of X on Y (<em>c</em>) for the multilevel model differs in important ways from the single-level (between-subject) calculations (eqn. 1). To obtain the population-level mediation effect, we must add the covariance of <span class="math inline">\(a_j\)</span> and <span class="math inline">\(b_j\)</span> to the product of the population-level <em>a</em> and <em>b</em> <span class="citation">(as shown by Kenny et al., 2003, eqn. 9)</span>:</p>
<span class="math display">\[\begin{equation}
me = ab + \sigma_{a_{j}b_{j}} .
\end{equation}\]</span>
<p><span class="math inline">\(\sigma_{a_{j}b_{j}}\)</span>, the covariance of <span class="math inline">\(a_j\)</span> and <span class="math inline">\(b_j\)</span>, is an element of the covariance matrix <span class="math inline">\(\Sigma\)</span>, and indicates the degree to which subjects with (say) greater values of <span class="math inline">\(a_j\)</span> are likely to have greater values of <span class="math inline">\(b_j\)</span> (in the case where the covariance is positive). Tofighi et al. noted that this covariance term can indicate an omitted variable that interacts with the <em>a</em> and <em>b</em> slopes, and therefore including it in the model leads to a more general model that allows misspecification of the model at the between subject level <span class="citation">(Tofighi, West, &amp; MacKinnon, 2013)</span>. These authors suggested that researchers estimate the model both with and without this covariance term <span class="citation">(Tofighi et al., 2013, p. 301)</span>, but in our view it is more straightforward to allow this parameter to be estimated from the data. Note, however, that researchers can effectively force this parameter to be zero by specifying a prior on it that spikes at zero (see below), but we don’t recommend this approach unless there is abundant prior information to suggest such a model. This covariance is illustrated in Figure @ref(fig:template-multilevel-mediation), with a double-headed arrow connecting <span class="math inline">\(a_j\)</span> and <span class="math inline">\(b_j\)</span>.</p>
<p>Finally, the population-level total effect of X on Y is given by</p>
<span class="math display">\[\begin{equation}
c = me + c' .
\end{equation}\]</span>
<p>The software also allows estimating the same multilevel mediation model, but for a binary Y variable (coded as 0s and 1s.) In this case, the model for Y (equations 4 &amp; 5) is a multilevel logistic regression:</p>
<span class="math display">\[\begin{equation}
Y_{ij} \sim Bernoulli(\mu_{Y_{ij}})
\end{equation}\begin{equation}
\mu_{Y_{ij}} = \frac{1}{1 + exp(-\eta_{Y_{ij}})}
\end{equation}\begin{equation}
\eta_{Y_{ij}} = (d_Y + u_{dY_j}) + (c' + u_{c'_j}) X_{ij} + (b + u_{b_j}) M_{ij}.
\end{equation}\]</span>
<p>The Bernoulli distribution in equation 9 is the Binomial distribution for a single trial.</p>
</div>
</div>
<div id="alternatives-to-multilevel-models" class="section level2">
<h2 class="hasAnchor">
<a href="#alternatives-to-multilevel-models" class="anchor"></a>Alternatives to multilevel models</h2>
<p>Although multilevel modeling is not the only approach to within-subject mediation, we believe that in the types of experiments most commonly employed in cognitive psychology and neuroscience, it is the most parsimonious and applicable mediation model.</p>
<p>A common alternative to multilevel modeling in within-subject mediation is longitudinal modeling, where change processes within individuals are modelled to occur over time <span class="citation">(Cheong, MacKinnon, &amp; Khoo, 2003; Cole &amp; Maxwell, 2003; MacKinnon, 2008; Selig &amp; Preacher, 2009)</span>. While a tremendously valuable approach in many areas of psychology, longitudinal models are less relevant in cognitive psychology and neuroscience, because experiments in these fields rarely track participants over time. Instead, experimental conditions are usually randomised trial-wise (or block-wise), and the experiments usually are less than an hour or two in duration, meaning that any possible change within individuals occurs repeatedly over the course of the experiment (when conditions change across trials) with no meaningful purely temporal pattern with respect to the causal effect.</p>
<p>Another method of addressing mediation in within-subject designs focuses on using change scores between experimental conditions <span class="citation">(Judd, Kenny, &amp; McClelland, 2001; Montoya &amp; Hayes, 2017)</span>, a valuable approach for experiments where participants provide only two measures. This method was recently advanced to include designs with control groups <span class="citation">(Valente &amp; MacKinnon, 2017)</span>. While useful for e.g. pre-post-test designs, this method does not easily address designs where the manipulated variable (X) continuous, or where participants are measured more than twice.</p>
<p>While useful in many situations, these other approaches to within-subject mediation are less practical and applicable than multilevel models in the context of cognitive psychology and neuroscience experiments. Therefore, we have decided to focus and implement a multilevel modeling approach to within-subject mediation.</p>
</div>
<div id="bayesian-estimation" class="section level2">
<h2 class="hasAnchor">
<a href="#bayesian-estimation" class="anchor"></a>Bayesian estimation</h2>
<p>Traditional procedures of estimating (within-subject) mediation models have focused on various frequentist methods, such as Ordinary Least Squares (OLS) and Maximum Likelihood Estimation (MLE). We instead advocate—and implement in the software package discussed below—Bayesian estimation, because it offers several advantages over these conventional methods. The benefits include the natural incorporation of uncertainty in estimated parameters in the form of a posterior distribution, and the probability interpretation afforded by it; the ability to incorporate prior information in the statistical model; and a more natural interpretation of multilevel models. We discuss these benefits below, then highlight some similarities of the Bayesian method to classical procedures before briefly introducing the precise method by which the Bayesian estimation is conducted in our programming package.</p>
<p>Traditional MLE methods for assessing (multilevel) regression models, such as those described above, provide point estimates and standard errors of the estimated parameters, which are in turn based on assumptions about the parameters’ sampling distributions, and from which Confidence Intervals can be calculated. In contrast, Bayesian analyses provide, for each parameter, full posterior probability distributions of plausible parameter values, and therefore directly intepretable representations of uncertainty <span class="citation">(Kruschke, 2014)</span>.</p>
<p>This fact is important when the investigation focuses on transformations of the estimated parameters at multiple levels, such as equations 7 and 8, because the uncertainty in the estimated parameters is conveniently carried forward to uncertainty in the transformations of the estimated parameters, such as <em>c</em>, <em>me</em> and <em>pme</em> (at both levels) in the multilevel mediation model. The posterior distributions can then be summarized by X% Credible Intervals or displayed visually to effectively communicate the relative plausibilities of various (transformed) parameter values. We believe the visual inspection of histograms and violin plots (Figures @ref(fig:example1-pop-hist) and @ref(fig:example1-pop-violin)) can benefit inference by helping users focus on distributions of plausible values, instead of point estimates. Visual inspection of the distribution of plausible values is especially important when the underlying distribution may be non-Gaussian, such as for indirect effects (or <em>pme</em>) in mediation, or when sample sizes are small.</p>
<p>Further, unlike the standard error given by MLE methods, the Bayesian posterior distribution is a probability distribution and allows statements of relative probabilities of parameter values. For instance, we often wish to discuss the plausibility of various parameter values, and our subjective confidence in these values. The posterior distribution obtained by a Bayesian analysis allows just that: Throughout this article we refer to “X% most plausible values”, and “credible” parameter values. These statements can be made based on summaries of the posterior distribution, such as the Credible Interval, which contains some percentage of the central values of the distribution. Confidence Intervals based on more common frequentist estimation methods (such as MLE) do not allow such statements of plausibility or subjective confidence, although they are sometimes (wrongly) so interpreted <span class="citation">(Morey, Hoekstra, Rouder, Lee, &amp; Wagenmakers, 2015)</span>.</p>
<p>The Bayesian framework also allows incorporating prior information in the statistical model. When prior information on the magnitudes of parameters is available, it can be naturally incorporated in the analysis, thus improving the estimates. This information can come from expertise in the field of study, earlier studies, or knowledge about the natural constraints in the data. For example, researchers are sometimes aware of limits beyond which parameters are unlikely to be found; this information can be incorporated in the form of a prior distribution which will decrease the variance of the estimate. Information used in this manner is sometimes called a “regularizing” prior, and can be very useful especially in contexts when the data are uninformative about the parameter <span class="citation">(McElreath, 2016)</span>.</p>
<p>A related benefit of incorporating prior information into a statistical model relates to the stability of the estimated parameters. A well-known problem with MLE methods in the context of multilevel models is that point estimates of the between-person heterogeneity parameters (often denoted <span class="math inline">\(\tau\)</span>, see equation 6) cannot be distinguished from zero, even though the parameter’s likelihood function contains a considerable range of non-zero values. A consequence of this is that with MLE the person-level parameters conditional on the zero heterogeneity would be erroneously estimated as identical. This situation occurs especially in applying generalized multilevel models, such as logistic regression. However, the Bayesian analysis provides a distribution of values for the heterogeneity parameter, which consequently is not “stuck” at zero and thus allows the subject-level parameters to vary. In these situations, the data can be relatively uninformative about the actual value of the parameter, and the posterior distribution may be unnecessarily wide.</p>
<p>In addition, when this happens, the Bayesian analysis allows including prior information in the form of a heavy tailed distribution, such as Cauchy with appropriate hyperparameters <span class="citation">(Gelman, 2006)</span>. This information can then effectively regularize the inference toward more realistic values, and thereby allow estimating the between-person heterogeneity parameter even in situations where MLE methods fail and the data are relatively uninformative about the underlying parameter values.</p>
<p>Although the topic is beyond the scope of this article, prior information allows Bayesian hypothesis testing in a straightforward manner using Bayes Factors. Bayes Factors can be thought of as quantifying the “extent to which data cause revision in belief” <span class="citation">(Kass &amp; Raftery, 1995; Rouder, Morey, Verhagen, Province, &amp; Wagenmakers, 2016, p. 533)</span> where “belief” is the prior probability distribution. Furthermore, Bayes Factors can be fairly easily estimated using MCMC samples (see below) using the Savage-Dickey density ratio method; details are given by Wagenmakers et al. <span class="citation">(2010)</span>.</p>
<p>Multilevel mediation is both conceptually and computationally significantly more complicated than single-level mediation. One conceptual difficulty is in how the parameters are interpreted at various levels of analysis: Classical methods consider the upper-level parameters as “fixed”, and the lower-level parameters as “random”. This may not be a fundamental problem, but at least presents difficulties in teaching and communication <span class="citation">(see footnote 2 in Gelman &amp; Hill, 2007, p. 245 for an exposition of the problem; see also Yuan &amp; MacKinnon, 2009, p. 312)</span>. In the Bayesian context, in contrast, all estimated quantities—irrespective of their level in the model’s hierarchy—are considered random. In the context of the multilevel mediation model, the upper- or population-level parameters can then be considered as empirically informed priors for the lower- or subject-level parameters <span class="citation">(equation 6; Gelman &amp; Hill, 2007)</span>.</p>
<p>On the computational side, conventional methods are often more difficult to apply to complex models, such as multilevel mediation <span class="citation">(Kenny et al., 2003; Yuan &amp; MacKinnon, 2009)</span>. On the other hand, Bayesian methods allow for a relatively straightforward estimation, especially when it is implemented with efficient MCMC methods (as discussed below). Although out of the scope of this manuscript, the Bayesian method will easily fit more complicated models with large numbers of covariates, levels of analysis, and parameter transformations—even in situations where more traditional MLE methods may fail or be too difficult to implement in practice.</p>
<div id="similarities-of-frequentist-and-bayesian-methods" class="section level3">
<h3 class="hasAnchor">
<a href="#similarities-of-frequentist-and-bayesian-methods" class="anchor"></a>Similarities of Frequentist and Bayesian Methods</h3>
<p>Having detailed some benefits of a Bayesian approach to estimating the multilevel model, is is also important to be aware of some important similarities between results obtained with Bayesian and more traditional MLE based methods. For one, when the sample size is very large, and the sampling error correspondingly small, the point estimate of a parameter can be considered a sufficient description of the posterior distribution <span class="citation">(Gelman et al., 2013)</span>. However, in practice sample sizes are rarely that large.</p>
<p>A more important similarity between classical and Bayesian methods is that if no prior information is included (<span class="math inline">\(\theta \sim U(-\infty, \infty)\)</span>), and the model estimation presents no problems, the obtained intervals often have identical bounds. This fact has led some authors to suggest that a classical confidence interval can sometimes be given a Bayesian interpretation <span class="citation">(Gelman et al., 2013, sec. 4.5)</span>. Notice, however, that we would rarely want to give a Bayesian interval a frequentist interpretation.</p>
<p>Furthermore, under similar assumptions as given above, the frequentist one-sided <em>p</em>-value corresponds to Bayesian posterior probabilities (that a parameter is greater or smaller than a comparison value, such as zero.) <span class="citation">(Marsman &amp; Wagenmakers, 2016)</span>. However, the probability interpretation naturally afforded to the Bayesian quantity seems to us to suggest its conceptual superiority, at least insofar as its interpretation does not immediately invite a binary significant-or-not attitude <span class="citation">(Gelman et al., 2013, p. 95)</span>. As a side note, the two-sided <em>p</em>-value does not have a straightforward Bayesian counterpart.</p>
<p>We are not the first to suggest the use of Bayesian methods in mediation analyses: Yuan and MacKinnon <span class="citation">(Yuan &amp; MacKinnon, 2009)</span> discussed using it for single- and multi-level mediation analyses, and provided copy-and-paste WinBUGS code for conducting the analyses. Another paper discussed the use and benefits of Bayesian methods in the specific context of moderated mediation <span class="citation">(Wang &amp; Preacher, 2015)</span>. To further these efforts, we provide a fully functional software package for conducting Bayesian multi-level mediation analyses in a common and free programming enviroment, using state of the art Bayesian estimation procedures, which we turn to next.</p>
</div>
<div id="mcmc-and-stan" class="section level3">
<h3 class="hasAnchor">
<a href="#mcmc-and-stan" class="anchor"></a>MCMC and Stan</h3>
<p>The computer program we provide and discuss below uses Markov Chain Monte Carlo (MCMC) procedures as implemented in the Stan<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> modeling software <span class="citation">(Stan Development Team, 2016b)</span> to fit the multilevel mediation model. MCMC is a class of computational procedures that allow approximating a probability distribution by drawing random samples from it <span class="citation">(for an excellent introduction to MCMC, see van Ravenzwaaij, Cassey, &amp; Brown, 2016)</span>. This technique is extremely valuable for Bayesian inference, because complex multidimensional posterior distributions are often difficult or impossible to obtain with analytic calculations.</p>
<p>Stan’s effective MCMC algorithms <span class="citation">(No-U-Turn Sampler, Hamiltonian Monte Carlo; Hoffman &amp; Gelman, 2014)</span> are well suited for the problems presented in multilevel mediation models, such as large numbers (potentially hundreds or thousands) of parameters at multiple levels. Unlike early popular MCMC algorithms that relied on Gibbs sampling (BUGS, JAGS), Stan’s Hamiltonian Monte Carlo is very effective even when the posterior distributions are highly correlated, making it especially useful for path analyses—such as mediation—and other more complex structural models.</p>
<p>Furthermore, the Stan language allows placing priors on correlation matrices and standard deviations, instead of (co)variances, making (arguably) the prior specification easier, as discussed next.</p>
</div>
<div id="prior-distributions-on-parameters" class="section level3">
<h3 class="hasAnchor">
<a href="#prior-distributions-on-parameters" class="anchor"></a>Prior distributions on parameters</h3>
<p>For Bayesian analysis, all population-level parameters must also be assigned prior distributions that represent the analyst’s state of knowledge and uncertainty, before seeing the data. The priors depend on the specifics of the data and context, and should be chosen by the researcher—although the priors often have little influence on the posterior distribution as the amount of data increases. The software package we introduce below has default values for the priors that we believe are reasonable, minimally informative priors in most contexts.</p>
<p>For the regression parameters, the prior distributions are zero-centered Gaussians, with user-defined standard deviations (defaults to 1000). Effectively, a zero-centered Gaussian with a small standard deviation “regularizes” (makes large positive or negative parameter values less plausible, a priori) the estimated parameters, thereby improving inference on average by preventing over-fitting <span class="citation">(McElreath, 2016)</span>. A more technical definition of what constitutes a “small” standard deviation depends on the theoretical context and measurement scale, but for large amounts of data, the values must be very small indeed to make a meaningful difference in the posterior. The default value of 1000 will have practically no impact on inference for data sets where effects are on the range of z-scores. If greater effects are plausible (say, a manipulation has an effect on the order of thousands of milliseconds), users may increase the value. The <span class="math inline">\(\sigma = 1000\)</span> we have placed on the population-level regression parameters considers values further away from zero as increasingly unlikely, such that 95% of the a priori most plausible values are between -1960 and 1960.</p>
<p>The second class of prior distributions relates to the variances and covariances of the subject-level effects. To allow placing priors directly on standard deviations and correlations, we construct the covariance matrix <span class="math inline">\(\Sigma\)</span> from a vector of standard deviations <span class="math inline">\(\tau\)</span> and a correlation matrix <span class="math inline">\(\Omega\)</span> <span class="citation">(Stan Development Team, 2016b)</span>. We use folded Cauchy distributions with user-defined scale parameters (defaults to 50) for the subject-level effects’ standard deviations <span class="citation">(Gelman, 2006; Gelman &amp; Hill, 2007)</span>. The Cauchy distribution is recommended for these parameters over alternatives, such as inverse-gamma or uniform distributions, especially when the number of clusters (subjects) is very small <span class="citation">(Gelman, 2006)</span>. Specifically, the hyperparameters of inverse-gamma prior distributions may be more difficult to specify when minimally or non-informative priors are desired, and uniform prior distributions may lead to overestimation of <span class="math inline">\(\tau\)</span>. The folded (positive-only) Cauchy distributions concern the variability of the effects between subjects: The default scale = 50 implies that increasingly large values of variation (standard deviation of their respective Gaussian distributions) between subjects are increasingly unlikely, such that a priori 50% of the most plausible values are under 50, and 95% are under 1272.</p>
<p>For the correlation matrix <span class="math inline">\(\Omega\)</span>, we use an <em>LKJ</em> prior with a user-defined shape parameter <span class="math inline">\(\nu\)</span> (defaults to 1) <span class="citation">(Lewandowski, Kurowicka, &amp; Joe, 2009; Stan Development Team, 2016b)</span>. With older MCMC sampling programs relying on Gibbs sampling, such as BUGS and JAGS, it was more convenient to use conjugate inverse Wishart distributions as priors on the covariance matrices. However, Stan doesn’t require conjugacy for multivariate priors, and it is often easier to think of plausible correlations rather than covariances, and we therefore use the <em>LKJ</em> prior distribution on <span class="math inline">\(\Omega\)</span>.</p>
<p>The default hyperparameter value for the <em>LKJ</em> prior (<span class="math inline">\(\nu\)</span> = 1) assigns equal plausibility across the range of possible values (-1 to 1), and values of <span class="math inline">\(\nu\)</span> greater than 1 increase the a priori skepticism of large correlations <span class="citation">(McElreath, 2016, p. 393)</span>. Because this distribution is relatively unknown and difficult to conceptualize (it is a distribution of matrices), Figure @ref(fig:lkj-prior-example) shows four sets of random draws from <em>LKJ</em> distributions with different values of <span class="math inline">\(\nu\)</span> <span class="citation">(McElreath, 2016)</span>.</p>
<pre><code>## Loading required package: rstan</code></pre>
<pre><code>## Loading required package: StanHeaders</code></pre>
<pre><code>## rstan (Version 2.16.2, packaged: 2017-07-03 09:24:58 UTC, GitRev: 2e1f913d3ca3)</code></pre>
<pre><code>## For execution on a local, multicore CPU with excess RAM we recommend calling
## rstan_options(auto_write = TRUE)
## options(mc.cores = parallel::detectCores())</code></pre>
<pre><code>## 
## Attaching package: 'rstan'</code></pre>
<pre><code>## The following object is masked from 'package:tidyr':
## 
##     extract</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre><code>## rethinking (Version 1.59)</code></pre>
<pre><code>## 
## Attaching package: 'rethinking'</code></pre>
<pre><code>## The following object is masked from 'package:purrr':
## 
##     map</code></pre>
<pre><code>## The following object is masked from 'package:papaja':
## 
##     se</code></pre>
<div class="figure">
<img src="bmlm-brm_files/figure-html/lkj-prior-example-1.png" alt="Histograms of 100000 random draws from the LKJ prior distribution for four values of $\nu$. " width="518.4"><p class="caption">
Histograms of 100000 random draws from the LKJ prior distribution for four values of <span class="math inline">\(\nu\)</span>.
</p>
</div>
<p>For general information on the choice of prior distributions, we refer the readers to excellent textbooks on Bayesian statistics <span class="citation">(Gelman, 2006; Gelman et al., 2013; Kruschke, 2014; McElreath, 2016)</span>. However, if users wish to estimate models without prior information, they can specify very large standard deviations to the Gaussian prior distributions and large scale parameters to the subject-level effects’ standard deviations <span class="citation">(Kruschke, 2014)</span>. Overall, we chose default values for the prior distributions which would have minimal impact on the resulting posterior distributions, given common ranges of data values and effect sizes. The default priors are easy to change by simply passing named arguments to the estimation function (as detailed below).</p>
</div>
</div>
</div>
<div id="software-package-for-bayesian-multilevel-mediation-bmlm" class="section level1">
<h1 class="hasAnchor">
<a href="#software-package-for-bayesian-multilevel-mediation-bmlm" class="anchor"></a>Software package for Bayesian multilevel mediation: bmlm</h1>
<p>We developed a free open-source software package (“<strong>bmlm</strong>” for Bayesian Multi-Level Mediation) for the R programming language <span class="citation">(R Core Team, 2016)</span> for easy estimation, summarizing, and plotting the results of the multilevel mediation model presented above <span class="citation">(Vuorre, 2016)</span>. The software can be installed from within the R environment (source code, detailed installation and use instructions are provided online at the package’s website <a href="https://github.com/mvuorre/bmlm" class="uri">https://github.com/mvuorre/bmlm</a>). To install the software package, please ensure that you have the latest versions of R and Xcode with command line tools (OS X users) or Rtools (Windows users). Then run the following command in the R console (the installation process may take a few minutes, because the models are compiled to C++ during installation):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"bmlm"</span>)</code></pre></div>
<p>After the package has been installed, it must be loaded to the current R workspace to make the functions contained in it available to the user.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bmlm)</code></pre></div>
<p>Next, we illustrate the functionality and use of <strong>bmlm</strong> with an empirical example.</p>
<div id="example-judgments-of-performance-in-a-video-game-task" class="section level2">
<h2 class="hasAnchor">
<a href="#example-judgments-of-performance-in-a-video-game-task" class="anchor"></a>Example: Judgments of performance in a video game task</h2>
<p>In a series of experiments, Metcalfe and colleagues have examined the informational bases of people’s judgments of control; that is, to what extent various experimental manipulations in a computer game task influence people’s experiences of control <span class="citation">(Metcalfe &amp; Greene, 2007)</span>. In these experiments, participants play an arcade style computer game, in which they use the computer mouse to move a game cursor (a light square) horizontally on the bottom of the screen, while Xs and Os fall from top to bottom of the screen. The objective of the game is to catch as many falling Xs as possible, while avoiding all the falling Os. After each game trial (about 20 seconds), the participants provide a judgment of their experienced control using an analog slider scale. These ratings have been found to be highly sensitive to various manipulations of the game, such as artificially introduced spatial and temporal discrepancies between the mouse and square movements, and the speed of the falling Xs and Os <span class="citation">(Metcalfe, Eich, &amp; Castel, 2010; Vuorre &amp; Metcalfe, 2016)</span>. Additionally, the participants have provided Judgments of Performance (JoP), their subjective evaluations of how well they did in the game on each trial, by using an analog slider scale. Here, we focus on how these JoPs are influenced by a specific experimental manipulation in this computer game task.</p>
<p>One experiment introduced, on some trials, a small temporal lag (250ms) between the participant’s mouse movements, and the movements of the game cursor on the screen <span class="citation">(Metcalfe et al., 2010, Experiment 1)</span>. This manipulation led to a reliable decrement in the players’ ratings of performance. In the analysis below we ask: <em>“How does the temporal lag between one’s mouse movements, and the movements of the game cursor, decrease ratings of performance?”</em> To answer this question, we propose a straightforward mediational explanation: The temporal lag decreases performance (as measured by <em>hit rate</em>, the percentage of Xs caught in a trial), and people’s Judgments of Performance depend on their hit rates. In other words, we expect that hit rate (performance) completely mediates temporal lag’s effect on judgments of performance. This hypothesis implies that people are making metacognitively accurate judgments of performance, by basing their performance judgments on an actual performance signal (hit rate), rather than, say, a general feeling of abnormally delayed mouse control.</p>
</div>
<div id="data-set" class="section level2">
<h2 class="hasAnchor">
<a href="#data-set" class="anchor"></a>Data set</h2>
<p>Multilevel models assume that the observed variables have at least two potential levels of variation. Because temporal lag was experimentally manipulated within subjects, it does not vary between subjects. On the other hand, hit rates (HR) vary both between and within participants: At the lower (within-person) level, HR varies from trial to trial. At the upper level, we may also expect that HR varies, on average, between participants. We are most interested in the within-person process, and therefore it is useful to transform the variables such that these two levels are explicitly separated from each other <span class="citation">(Bolger &amp; Laurenceau, 2013)</span>. Notice that this transformation is not strictly required, but this reasoning suggests that it is often useful and meaningful in data sets where the predictor values vary both between and within subjects. We first averaged the grand-mean-centered trial-level HR for each person to create a between-person component of HR. We subtracted these means from the raw HR to create within-subject trial-by-trial deviations from the subject-means that represent an entirely within-person version of HR. Isolating the within-person process from variables can be done by using <strong>bmlm</strong>’s <code><a href="../../reference/isolate.html">isolate()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MEC2010 &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/isolate.html">isolate</a></span>(<span class="dt">d =</span> MEC2010,
                   <span class="dt">by =</span> <span class="st">"subj"</span>,  
                   <span class="dt">value =</span> <span class="st">"hr"</span>)  </code></pre></div>
<p>The <code><a href="../../reference/isolate.html">isolate()</a></code> function takes three arguments. On the first row, we specify the data set to be <code>MEC2010</code>, which contains data described in <span class="citation">(Metcalfe et al., 2010)</span> and is included with the <strong>bmlm</strong> package. The next line specifies the column containing values to isolate the within- and between person processes by (the subject numbers). Finally, the third line identifies the variable to be isolated. After this transformation, the example data frame is ready, and can be seen in Table @ref(tab:example1-data-table).</p>
<caption>
(#tab:example1-data-table)<em>First six rows of the example data set.</em>
</caption>
<table class="table">
<thead><tr class="header">
<th align="left">subj</th>
<th align="left">lag</th>
<th align="left">hr</th>
<th align="left">jop</th>
<th align="left">hr_cw</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">36.7</td>
<td align="left">30</td>
<td align="left">-23.3</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">50.0</td>
<td align="left">80</td>
<td align="left">-10.0</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">0</td>
<td align="left">56.7</td>
<td align="left">90</td>
<td align="left">-3.3</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">56.7</td>
<td align="left">32</td>
<td align="left">-3.3</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">56.7</td>
<td align="left">50</td>
<td align="left">-3.3</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">0</td>
<td align="left">70.0</td>
<td align="left">76</td>
<td align="left">10.0</td>
</tr>
</tbody>
</table>
<center>
<em>Note.</em> Variables with “_cw” are centered within-person.
</center>
<p>Table @ref(tab:example1-data-table) illustrates the structure and variables of the example data set. Each participant (43 individuals) is assigned a unique id number (<code>subj</code>); the two experimental conditions are represented by a dichotomous indicator variable, where 1 indicates a lag trial (<code>lag</code>); <code>hr</code> is the raw percent of Xs caught in a trial; and <code>jop</code> is the judgment of performance (from low [1] to high [100]). Finally, <code>hr_cw</code> is the isolated within-subject component of hit rate. All the variables must be numeric; if the experiment contained two conditions, as in the example here, the conditions would need to be dummy coded with integers. The data set contains 8 observations per individual, 4 in the lag condition, and 4 in a control condition. Eight observations per person may seem a prohibitively small sample, but because the multilevel model pools uncertainty across subjects, we are able to estimate the within-subject causal process with these data, as shown below.</p>
</div>
<div id="estimating-the-multilevel-mediation-model-with-bmlm" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-the-multilevel-mediation-model-with-bmlm" class="anchor"></a>Estimating the multilevel mediation model with bmlm</h2>
<p>To estimate the multilevel mediation model with bmlm, users need to specify the data (an R data frame) in the current R environment, and variables within the data frame identifying individuals, and the X, M, and Y variables. Here, <code>MEC2010</code> is our data frame, <code>subj</code> the column identifying individuals, and <code>lag</code>, <code>hr_cw</code> and <code>jop</code> the X, M, and Y variables, respectively. These variables are entered into a call to the <code><a href="../../reference/mlm.html">mlm()</a></code> function, which estimates the model using Stan’s MCMC algorithms <span class="citation">(Stan Development Team, 2016b)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/mlm.html">mlm</a></span>(<span class="dt">d =</span> MEC2010, 
           <span class="dt">id =</span> <span class="st">"subj"</span>, 
           <span class="dt">x =</span> <span class="st">"lag"</span>, 
           <span class="dt">m =</span> <span class="st">"hr_cw"</span>, 
           <span class="dt">y =</span> <span class="st">"jop"</span>,
           <span class="dt">iter =</span> <span class="dv">10000</span>, <span class="dt">cores =</span> <span class="dv">4</span>)</code></pre></div>
<pre><code>## Estimating model, please wait.</code></pre>
<pre><code>## trying deprecated constructor; please alert package maintainer</code></pre>
<p>This function has two other important features, the control of prior distributions and various controls of the underlying Stan MCMC procedures. As is usual in R, more information can be found by entering <code><a href="../../reference/mlm.html">?mlm</a></code> in the R console. Although the software package sets default priors, users may also input arguments identifying the prior parameters they would like to change (see the documentation included with the software package, or the package’s website, for details). Users may also control the behavior of the underlying MCMC sampler; here, to ensure stable results we increased the number of iterations from the default of 2,000 to 10,000, and ran the program simultaneously on 4 CPU cores.</p>
<p>Depending on the size of the data set and your computer, the MCMC sampling may take from a few seconds to several minutes. By default, <code><a href="../../reference/mlm.html">mlm()</a></code> runs 4 MCMC chains, and uses the first half of each chain for warmup <span class="citation">(Stan Development Team, 2016b)</span>. The <code>iter</code> argument specifies the total number of iterations per chain, so this example results in 20,000 samples (4 x 10,000 / 2) from the model’s posterior distribution. During and after sampling from the posterior distribution, Stan will print progress information in the R console. Occasionally, these prints may include warnings about abnormal parameter values, but these are usually not a cause for worry but simply a part of the random MCMC sampling procedure. After the procedure ends, and the model has been estimated (the desired number of posterior samples have been obtained), the estimated parameters can be summarized using <strong>bmlm</strong>’s functions.</p>
</div>
<div id="summarizing-the-multilevel-mediation-model" class="section level2">
<h2 class="hasAnchor">
<a href="#summarizing-the-multilevel-mediation-model" class="anchor"></a>Summarizing the multilevel mediation model</h2>
<div id="population-level-estimates" class="section level3">
<h3 class="hasAnchor">
<a href="#population-level-estimates" class="anchor"></a>Population-level estimates</h3>
<p>We first focus on the population-level parameters of the multilevel model. These estimates describe the results of the mediation analysis for the average person, and are often the parameters of greatest interest. Users may print the model’s focal estimated parameters directly to the R console by running <code><a href="../../reference/mlm_summary.html">mlm_summary(fit)</a></code>, where <code>fit</code> is the R object containing the estimated model:</p>
<caption>
(#tab:example1-summary)<em>Summary of results.</em>
</caption>
<table class="table">
<thead><tr class="header">
<th align="left">Parameter</th>
<th align="left">Mean</th>
<th align="left">SE</th>
<th align="left">Median</th>
<th align="left">2.5%</th>
<th align="left">97.5%</th>
<th align="left">n_eff</th>
<th align="left">Rhat</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">a</td>
<td align="left">-35.51</td>
<td align="left">1.29</td>
<td align="left">-35.51</td>
<td align="left">-38.04</td>
<td align="left">-32.95</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
<tr class="even">
<td align="left">b</td>
<td align="left">0.95</td>
<td align="left">0.07</td>
<td align="left">0.95</td>
<td align="left">0.80</td>
<td align="left">1.09</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
<tr class="odd">
<td align="left">cp</td>
<td align="left">-0.56</td>
<td align="left">2.82</td>
<td align="left">-0.55</td>
<td align="left">-6.12</td>
<td align="left">4.94</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
<tr class="even">
<td align="left">me</td>
<td align="left">-33.63</td>
<td align="left">2.85</td>
<td align="left">-33.58</td>
<td align="left">-39.32</td>
<td align="left">-28.22</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
<tr class="odd">
<td align="left">c</td>
<td align="left">-34.18</td>
<td align="left">2.30</td>
<td align="left">-34.16</td>
<td align="left">-38.78</td>
<td align="left">-29.72</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
<tr class="even">
<td align="left">pme</td>
<td align="left">0.99</td>
<td align="left">0.08</td>
<td align="left">0.98</td>
<td align="left">0.83</td>
<td align="left">1.15</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
</tbody>
</table>
<center>
<em>Note.</em> SE (for Standard Error) is the posterior standard deviation.
</center>
<p>The output in Table @ref(tab:example1-summary) consists of the main population-level parameters of the mediation model. The names correspond to the parameters introduced in Figures @ref(fig:template-mediation-plot) and @ref(fig:template-multilevel-mediation), and equations 2-8 (<em>cp</em> is <em>c’</em>, <em>pme</em> is proportion of effect that is mediated [see below]). For each parameter, the output shows the posterior mean, standard deviation (abbreviated SE for standard error), and median (which may be a more representative point estimate for skewed posterior distributions.) “2.5%” and “97.5%” are the lower and upper limits of a 95% Credible Interval, which is the central 95% of the corresponding distribution. The limits of the CI can be controlled by specifying the <code>level</code> argument of this function, e.g. an 80% CI would be obtained with <code>level = .8</code>. <em>n_eff</em> indicates the number of effective posterior samples, taking into account the MCMC chains’ autocorrelation; this value should be large to allow confident estimates of the quantities. Finally, <em>Rhat</em> is the potential scale reduction factor, and should be 1.00 for accurate estimates of the posterior distribution <span class="citation">(Gelman et al., 2013, pp. 285–288)</span>. If <em>n_eff</em> is too small, or <em>Rhat</em> not 1.00, simply increase the number of MCMC iterations and re-estimate the model using <code><a href="../../reference/mlm.html">mlm()</a></code>. We recommend to increase the number of iterations until <em>Rhat</em> is within .05 of 1, and although Gelman et al. <span class="citation">(2013)</span> suggest that <em>n_eff</em> greater than 10 or 100 is acceptable, in practice when extreme quantiles (such as 95% CIs) are of interest, we recommend increasing iterations until <em>n_eff</em> &gt; 100 (at least).</p>
<p>First, we interpret the total effect of temporal lag on judgments of performance (<em>c</em>, equation 8). 95% of the most plausible values of this parameter lie in the interval between -39 and -30, and the mean value of the posterior distribution is -34. Therefore, people gave about 34 points lower ratings of performance (on a scale from 1 to 100) in the lag condition versus the control condition, with 95% of the most plausible values ranging from -39 to -30. Our mediation hypothesis was that this effect would be mediated by hit rate. Therefore, we next focus on the magnitude of the mediation effect, the <em>me</em> parameter (equation 7). In support of our conjecture, <em>me</em> appears very strong, and of approximately equal magnitude to the total effect <em>c</em>. 95% of most plausible values of <em>me</em> lie between -39 and -28, and the mean value is -34. Further, after taking the hit rates into account, the direct effect of lag is approximately zero and has a narrow credibility interval (<em>cp</em> = -0.56, 95% CI [-6.12, 4.94]), indicating that the lag <span class="math inline">\(\rightarrow\)</span> JoP relationship is completely mediated by hit rate.</p>
<p>Multilevel models also naturally estimate the between-subject variability around the population-level estimates, and the covariance of the subject-level parameters (i.e. the so-called random effects). The variability is captured in the standard deviations of the subject-level effects (see eqn. 6 and <strong>Prior distributions on parameters</strong> above). These estimates are useful summaries of the heterogeneity and covariance of effects, and can be obtained from the model by calling <code>mlm_summary(fit, pars = "random"))</code>:</p>
<caption>
(#tab:random-effect-table)<em>Standard deviations of the regression parameters, and their covariance (and correlation).</em>
</caption>
<table class="table">
<thead><tr class="header">
<th align="left">Parameter</th>
<th align="left">Mean</th>
<th align="left">SE</th>
<th align="left">Median</th>
<th align="left">2.5%</th>
<th align="left">97.5%</th>
<th align="left">n_eff</th>
<th align="left">Rhat</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">tau_a</td>
<td align="left">1.62</td>
<td align="left">1.31</td>
<td align="left">1.32</td>
<td align="left">0.06</td>
<td align="left">4.91</td>
<td align="left">6,228</td>
<td align="left">1.00</td>
</tr>
<tr class="even">
<td align="left">tau_b</td>
<td align="left">0.18</td>
<td align="left">0.08</td>
<td align="left">0.19</td>
<td align="left">0.02</td>
<td align="left">0.33</td>
<td align="left">2,873</td>
<td align="left">1.00</td>
</tr>
<tr class="odd">
<td align="left">tau_cp</td>
<td align="left">4.34</td>
<td align="left">2.89</td>
<td align="left">4.01</td>
<td align="left">0.21</td>
<td align="left">10.73</td>
<td align="left">5,285</td>
<td align="left">1.00</td>
</tr>
<tr class="even">
<td align="left">covab</td>
<td align="left">-0.07</td>
<td align="left">0.17</td>
<td align="left">-0.02</td>
<td align="left">-0.54</td>
<td align="left">0.17</td>
<td align="left">11,201</td>
<td align="left">1.00</td>
</tr>
<tr class="odd">
<td align="left">corrab</td>
<td align="left">-0.15</td>
<td align="left">0.39</td>
<td align="left">-0.18</td>
<td align="left">-0.81</td>
<td align="left">0.66</td>
<td align="left">20,000</td>
<td align="left">1.00</td>
</tr>
</tbody>
</table>
<center>
<em>Note.</em>
</center>
<p>For instance, <em>tau_a</em> in Table @ref(tab:random-effect-table) is the estimated standard deviation of the lag <span class="math inline">\(\rightarrow\)</span> hit rate relationship in the population. Because posterior distributions of standard deviations tend to be non-normal, instead of a point estimate (the posterior mean or median) we focus on the 95% CI: 95% of the most plausible values of <em>tau_a</em> are between 0.06 and 4.91. In context of an <em>a</em> effect of -35, the between-subject variation of this effect is very small. To obtain summaries of other parameters in the model, such as subject-specific effects, users need to enter the names of the parameters to the <code>pars</code> argument of <code><a href="../../reference/mlm_summary.html">mlm_summary()</a></code>.</p>
</div>
</div>
<div id="visualizing-the-estimated-parameters" class="section level2">
<h2 class="hasAnchor">
<a href="#visualizing-the-estimated-parameters" class="anchor"></a>Visualizing the estimated parameters</h2>
<p><strong>bmlm</strong> offers quick access to summary plots from estimated models. To draw a path diagram with the variable names, and estimated path parameters as means and X% CIs (default 95%), use <code><a href="../../reference/mlm_path_plot.html">mlm_path_plot()</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/mlm_path_plot.html">mlm_path_plot</a></span>(fit, <span class="dt">xlab =</span> <span class="st">"Lag"</span>, <span class="dt">mlab =</span> <span class="st">"Hit Rate"</span>, <span class="dt">ylab =</span> <span class="st">"JoP"</span>)</code></pre></div>
<div class="figure">
<img src="bmlm-brm_files/figure-html/example1-path-plot-1.png" alt="Path diagram with point estimates (posterior means) of the parameters and associated 95 percent Credible Intervals (in square brackets below the point estimates). Under each estimated average effect, 'SD' shows the associated effect's standard deviation, which indicates the degree to which that effect varies between people (in standard deviation units)." width="499.2"><p class="caption">
Path diagram with point estimates (posterior means) of the parameters and associated 95 percent Credible Intervals (in square brackets below the point estimates). Under each estimated average effect, ‘SD’ shows the associated effect’s standard deviation, which indicates the degree to which that effect varies between people (in standard deviation units).
</p>
</div>
<p>Second, although the path plot affords a rapid visual display of the main conclusions of the model, it is often more informative to plot the parameters themselves. <strong>bmlm</strong> offers three default plots of the parameters, illustrated below. To access these figures, use the <code><a href="../../reference/mlm_pars_plot.html">mlm_pars_plot()</a></code> function. This function draws histograms, violin plots, or point estimates with CIs, of the estimated parameters. The type of the plot can be specified by setting the <code>type = X</code> argument to this function call, where X is either <code>"hist"</code> (Figure @ref(fig:example1-pop-hist)), “<code>violin</code>” (Figure @ref(fig:example1-pop-violin)), or “<code>coef</code>” (Figure @ref(fig:example1-subj-coefs)).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/mlm_pars_plot.html">mlm_pars_plot</a></span>(fit, 
              <span class="dt">type =</span> <span class="st">"hist"</span>, 
              <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">"tau_a"</span>, <span class="st">"tau_b"</span>, <span class="st">"covab"</span>),  <span class="co"># Which parameters</span>
              <span class="dt">nrow =</span> <span class="dv">1</span>)  <span class="co"># Number of rows for multiple histograms</span></code></pre></div>
<pre><code>## No id variables; using all as measure variables</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure">
<img src="bmlm-brm_files/figure-html/example1-pop-hist-1.png" alt="Histograms of the marginal posterior distributions of the standard deviations of a and b (left, middle), and the a-b covariance (right). Quick visual inspection tells us that these distributions are unlikely to be Gaussian, and therefore using the distributions' means or standard deviations as numerical summaries may be misleading. It is better to interpret the entire distribution." width="672"><p class="caption">
Histograms of the marginal posterior distributions of the standard deviations of a and b (left, middle), and the a-b covariance (right). Quick visual inspection tells us that these distributions are unlikely to be Gaussian, and therefore using the distributions’ means or standard deviations as numerical summaries may be misleading. It is better to interpret the entire distribution.
</p>
</div>
<p>We prefer displaying the main parameters of interest as “violin” plots (also known as “cat’s eye” plots, Figure @ref(fig:example1-pop-violin)). These offer a view of the distributions such that the width of the shape is proportional to the frequency of those values. In other words, the “violins” are filled density curved turned sideways and mirrored. The violin shapes in Figure @ref(fig:example1-pop-violin) illustrate that the most plausible values of <em>cp</em> (population-level direct effect of lag on JoPs), for example, are found near zero, and offer a visual depiction of the relative credibility (width of violin) of the parameter values (y axis). The extremely thin tails of <em>cp</em> beyond about ±5 indicate that these values are implausible. The code snippet below also illustrates that the object returned by <code><a href="../../reference/mlm_pars_plot.html">mlm_pars_plot()</a></code> is a ggplot2 object, and can be further customized by functions in the ggplot2 R package <span class="citation">(Wickham, 2016)</span>. Here, we specify the y axis breaks to run from -50 to 10 in increments of five.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/mlm_pars_plot.html">mlm_pars_plot</a></span>(fit, 
              <span class="dt">type =</span> <span class="st">"violin"</span>, 
              <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">"a"</span>, <span class="st">"cp"</span>, <span class="st">"c"</span>, <span class="st">"me"</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">50</span>, <span class="dv">10</span>, <span class="dv">5</span>))</code></pre></div>
<pre><code>## No id variables; using all as measure variables</code></pre>
<div class="figure">
<img src="bmlm-brm_files/figure-html/example1-pop-violin-1.png" alt="Violin plots of the estimated parameters. Each dark violin shape is a mirrored top-down view of a density plot." width="384"><p class="caption">
Violin plots of the estimated parameters. Each dark violin shape is a mirrored top-down view of a density plot.
</p>
</div>
<p>Unlike more familiar point-and-error-bar representations of uncertainty, violin plots put visual emphasis on the relative plausibility of values within the distribution itself, and may therefore allow a more efficient display of information.</p>
<div id="subject-level-estimates" class="section level3">
<h3 class="hasAnchor">
<a href="#subject-level-estimates" class="anchor"></a>Subject-level estimates</h3>
<p>The multilevel model provides, for each person, their own mediation model with empirical Bayes estimates of the parameters. Numerical representations of these values would quickly overwhelm us, but a graphical representation of the subject-level parameter values offers valuable insight about the between-subject variability in the estimated effects. For example, the subject-specific values of <em>me</em> show relatively little variation, and indicate that the mediation effect is present for each individual person. To obtain subject-specific parameters, simply call the function with the parameter name prepended with “u_”. (We again specify the y axis breaks as in the Figure @ref(fig:example1-pop-violin).)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/mlm_pars_plot.html">mlm_pars_plot</a></span>(fit, 
              <span class="dt">type =</span> <span class="st">"coef"</span>, 
              <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">"u_me"</span>, <span class="st">"me"</span>),
              <span class="dt">level =</span> .<span class="dv">80</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">50</span>, <span class="dv">10</span>, <span class="dv">5</span>))</code></pre></div>
<pre><code>## No id variables; using all as measure variables</code></pre>
<div class="figure">
<img src="bmlm-brm_files/figure-html/example1-subj-coefs-1.png" alt="Coefficient plot of the person-level estimates of the mediation effect. Each square represents the mean of an individual's estimated ab parameter, and the lines cover the 80% CI of the parameters. By adjusting the 'pars' argument, we also include the average level estimate, which is automatically displayed in red." width="403.2"><p class="caption">
Coefficient plot of the person-level estimates of the mediation effect. Each square represents the mean of an individual’s estimated ab parameter, and the lines cover the 80% CI of the parameters. By adjusting the ‘pars’ argument, we also include the average level estimate, which is automatically displayed in red.
</p>
</div>
<p>Figure @ref(fig:example1-subj-coefs) displays the subject-level (black) and population-level (red) estimates of <em>me</em>, the mediation effect, and shows that while there is some variation in the subject-specific effects, there appears to be a strong mediation effect (indirect effect) for every person.</p>
</div>
</div>
<div id="mediation-with-binary-outcomes" class="section level2">
<h2 class="hasAnchor">
<a href="#mediation-with-binary-outcomes" class="anchor"></a>Mediation with binary outcomes</h2>
<p>Binary outcomes are common in cognitive psychology, such as in learning and memory experiments where the Y variable may be a binary indicator for a correct / incorrect or remembered / not remembered response. <strong>bmlm</strong> allows estimating the multilevel mediation model with binary outcomes, and assumes that the outcome variable is coded as 0s and 1s.</p>
<p>To illustrate how to estimate the model with a binary outcome variable, we created a binary (0/1) outcome variable in the current example data by within-person-median splitting the original outcome variable (Table @ref(tab:example-2-prep)). Some authors also recommend standardizing the M variable <span class="citation">(MacKinnon &amp; Dwyer, 1993; Winship &amp; Mare, 1983)</span>, but we omit standardizing M here for simplicity.</p>
<caption>
(#tab:example-2-prep)<em>Example data with a binary Y variable.</em>
</caption>
<table class="table">
<thead><tr class="header">
<th align="left">subj</th>
<th align="left">lag</th>
<th align="left">hr</th>
<th align="left">jop</th>
<th align="left">hr_cw</th>
<th align="left">jop_bin</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">36.67</td>
<td align="left">30</td>
<td align="left">-23.33</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">50.00</td>
<td align="left">80</td>
<td align="left">-10.00</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">0</td>
<td align="left">56.67</td>
<td align="left">90</td>
<td align="left">-3.33</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">56.67</td>
<td align="left">32</td>
<td align="left">-3.33</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">56.67</td>
<td align="left">50</td>
<td align="left">-3.33</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">0</td>
<td align="left">70.00</td>
<td align="left">76</td>
<td align="left">10.00</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<center>
<em>Note.</em> jop_bin is a within-person median split version of the original jop variable.
</center>
<p>Because Y is now binary, we must specify <code>binary_y = TRUE</code> when using <code><a href="../../reference/mlm.html">mlm()</a></code> to estimate the model. We also take the opportunity here to illustrate how to adjust the prior scale parameters when estimating the model. We assign the <em>b</em> parameter’s Gaussian prior distribution’s SD to 1. This (somewhat arbitrary) prior assumption means that our prior knowledge about <em>b</em> is described by a Gaussian distribution centered on zero with a standard deviation of 1. For example, if the estimated parameter was exactly 1, then the effect of one unit of <code>hr_cw</code> on the log-odds of <code>jop_bin</code> was 1; a rather implausibly large effect. In effect, this prior then a priori constrains plausible parameter values to be closer to zero as described by the <span class="math inline">\(N(0, 1)\)</span> distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_bin &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/mlm.html">mlm</a></span>(<span class="dt">d =</span> MEC2010, 
               <span class="dt">id =</span> <span class="st">"subj"</span>, 
               <span class="dt">x =</span> <span class="st">"lag"</span>, 
               <span class="dt">m =</span> <span class="st">"hr_cw"</span>, 
               <span class="dt">y =</span> <span class="st">"jop_bin"</span>,
               <span class="dt">binary_y =</span> <span class="ot">TRUE</span>, 
               <span class="dt">priors =</span> <span class="kw">list</span>(<span class="dt">b =</span> <span class="dv">1</span>),
               <span class="dt">cores =</span> <span class="dv">4</span>)</code></pre></div>
<pre><code>## Estimating model, please wait.</code></pre>
<pre><code>## trying deprecated constructor; please alert package maintainer</code></pre>
<p>The estimated model is now in an R object called <code>fit_bin</code>. All the summarizing and plotting functions illustrated above can be used with the binary Y model as well. However, all the model’s coefficients that refer to Y (and their transformations, such as the mediation effect) are products of a linear regression coefficient (path <em>a</em>), and a logistic regression coefficient (path <em>b</em>). These values are usually difficult to interpret, and we therefore recommend users to visualize the fitted values of the model.</p>
</div>
<div id="visualizing-the-models-fitted-values" class="section level2">
<h2 class="hasAnchor">
<a href="#visualizing-the-models-fitted-values" class="anchor"></a>Visualizing the model’s fitted values</h2>
<p>A helpful function for visualizing the fitted values is <code><a href="../../reference/mlm_spaghetti_plot.html">mlm_spaghetti_plot()</a></code>, which is used to draw “spaghetti” plots that show fitted values at the population- and subject-levels. Spaghetti plots make the relationships between the variables particularly salient, by plotting the model’s fitted values in the data space (i.e. the <em>b</em> path is plotted in probability space). We illustrate how to use this function below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/mlm_spaghetti_plot.html">mlm_spaghetti_plot</a></span>(
    <span class="dt">mod =</span> fit_bin,
    <span class="dt">d =</span> MEC2010,
    <span class="dt">x =</span> <span class="st">"lag"</span>, <span class="dt">m =</span> <span class="st">"hr_cw"</span>, <span class="dt">y =</span> <span class="st">"jop_bin"</span>, <span class="dt">id =</span> <span class="st">"subj"</span>,
    <span class="dt">fixed =</span> <span class="ot">TRUE</span>, <span class="dt">random =</span> <span class="ot">FALSE</span>, <span class="dt">binary_y =</span> <span class="ot">TRUE</span>, <span class="dt">n =</span> <span class="dv">20</span>)</code></pre></div>
<p>The input arguments to <code><a href="../../reference/mlm_spaghetti_plot.html">mlm_spaghetti_plot()</a></code> are the model (<code>mod</code>), the data frame used to fit the model (<code>d</code>), and the <code>X</code>, <code>M</code>, <code>Y</code>, and <code>id</code> variable names (as they are in the data). Further arguments allow the user to decide to visualize the population-level effects (<code>fixed</code>), subject-specific effects (<code>random</code>), or both. Finally, we also specified that the model has a binary outcome variable <code>binary_y = TRUE</code>, and ensured that the lines look smooth by specifying that the fitted lines should be evaluated along 20 points on the x-axis (<code>n = 20</code>).</p>
<p>The resulting figure (Figure @ref(fig:spaghetti-plot-binary-y)) is especially useful for understanding the model when Y is binary, because the estimated parameters referring to Y are in log-odds, and the mediation effect is a product of a linear coefficient and a log-odds coefficient. This visualization is directly interpretable because the slope of the <em>b</em> path is shown in probability space, and visualized such that the x-axis values are the fitted values of M from the a path regression, and thus carry the effect size of the <em>a</em> path to plausible effects of the <em>b</em> path. Finally, the gray shades surrounding the regression lines in both panels of the figure are by default 95% Credibility Intervals, but the percentage can be adjusted with the <code>level</code> argument of <code><a href="../../reference/mlm_spaghetti_plot.html">mlm_spaghetti_plot()</a></code>.</p>
<div class="figure">
<img src="bmlm-brm_files/figure-html/spaghetti-plot-binary-y-1.png" alt="Fitted values of the multilevel mediation model with a binary Y. Left panel: Population-level regression line for path a and its 95\%CI as a grey shade. Right panel: Population level regression line for path b in probability space, and its 95\%CI." width="672"><p class="caption">
Fitted values of the multilevel mediation model with a binary Y. Left panel: Population-level regression line for path a and its 95%CI as a grey shade. Right panel: Population level regression line for path b in probability space, and its 95%CI.
</p>
</div>
<p>The same function can also be used to display regression lines of the <em>a</em> and <em>b</em> paths for every individual in the study by setting the function’s argument <code>random = TRUE</code>. Figure @ref(fig:spaghetti-plot-b-binary-y) shows the resulting “spaghetti” plot. These figures are especially helpful in illustrating the heterogeneity of effects among participants, which in this study was very small.</p>
<div class="figure">
<img src="bmlm-brm_files/figure-html/spaghetti-plot-b-binary-y-1.png" alt="Fitted values of the multilevel mediation model with a binary Y, for every individual in the study. Left panel: Subject-specific regression lines for path a. Right panel: Subject-specific fitted values for path b in probability space." width="672"><p class="caption">
Fitted values of the multilevel mediation model with a binary Y, for every individual in the study. Left panel: Subject-specific regression lines for path a. Right panel: Subject-specific fitted values for path b in probability space.
</p>
</div>
</div>
<div id="estimating-the-magnitude-of-mediation" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-the-magnitude-of-mediation" class="anchor"></a>Estimating the magnitude of mediation</h2>
<p>While <em>me</em> and <em>c’</em> together provide information on the magnitude of the population-level mediation and direct effects, respectively, another approach to assessing the magnitude of mediation is to calculate the proportion of the total effect that is mediated, <span class="math inline">\(\frac{me}{c}\)</span> <span class="citation">(MacKinnon et al., 2007; MacKinnon, Warsi, &amp; Dwyer, 1995; Shrout &amp; Bolger, 2002)</span>.</p>
<pre><code>## No id variables; using all as measure variables</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure">
<img src="bmlm-brm_files/figure-html/example1-pme-plot-1.png" alt="MCMC samples from the posterior distribution of the population-level proportion of effect that is mediated." width="268.8"><p class="caption">
MCMC samples from the posterior distribution of the population-level proportion of effect that is mediated.
</p>
</div>
<p>Because the Bayesian framework provides a full multivariate posterior distribution, obtaining the posterior distribution of <span class="math inline">\(\frac{me}{c}\)</span> is straightforward. This quantity is saved in the estimated model as <em>pme</em>, for proportion mediation effect (or “proportion of effect that is mediated”). The resulting marginal posterior distribution from the current example is illustrated in Figure @ref(fig:example1-pme-plot). It is important to note that interpreting <em>pme</em> is straightforward only if the mediated and direct effects are of the same sign <span class="citation">(Shrout &amp; Bolger, 2002)</span>. For this, and other reasons, estimated values of <em>pme</em> may exceed 1 or be negative, and therefore do not represent a true proportion. We recommend interpreting values greater than 1 as 1. Although the usefulness of this metric can be disputed because it does not represent a true proportion, it can sometimes be useful—especially as a quick and rough estimate of the importance of the mediated effect—and we include it in the model’s output, but remind researchers to be cautious when interpreting it. Keeping this in mind, the posterior distribution of <em>pme</em> in Figure @ref(fig:example1-pme-plot) suggests that most plausible values are very close to 1, again reinforcing our conclusion of total mediation of lag’s effect on judgments of performance through hit rates.</p>
<p>Other effect size measures for mediated effects have also been proposed, such as <span class="math inline">\(\kappa^2\)</span>, which is a standardized effect size denoting the “proportion of the maximum possible indirect effect that could have occurred, had the constituent effects been as large as the design and data permitted” <span class="citation">(Preacher &amp; Kelley, 2011, p. 106)</span>. However, the usefulness and definition of the <span class="math inline">\(\kappa^2\)</span> metric has been contested for a number of reasons, including that it can decrease even though the underlying mediation effect increases <span class="citation">(Wen &amp; Fan, 2015)</span>.</p>
<p>Furthermore, non-standardized effect sizes are often easier to interpret, and as such can be more informative about the measures used in the experiment <span class="citation">(Baguley, 2009)</span>. Therefore, we recommend describing the results of multilevel mediation analyses using unstandardized effect sizes such as the coefficients <em>a</em>, <em>b</em>, <em>c’</em>, and their transformations such as <em>me</em>. This recommendation echoes Tukey’s note that “being so disinterested in our variables that we do not care about their units can hardly be desirable.” <span class="citation">(Tukey, 1969, p. 89)</span>.</p>
<p>In the case of a binary Y variable, the regression coefficients <em>b</em> and <em>c’</em> are more difficult to interpret directly, because they report unstandardized effect sizes in the log-odds scale. Consequently, the mediated effect <em>me</em> is a product of a linear effect on the data scale (<em>a</em>), and a linear effect on the log-odds scale (<em>b</em>). However, this complication reflects the fact that mediation effects are inherently combinations of many variables, and there may not be a single metric that adequately captures the mediation effect size in all situations <span class="citation">(Wen &amp; Fan, 2015)</span>.</p>
<p>Consequently, we recommend reporting not only the mediated effect <em>me</em>, but its constituent parts <em>a</em> and <em>b</em> as well (and covariance <span class="math inline">\(\sigma_{a_{j}b_{j}}\)</span>, if it is important in the current analysis). If the <em>a</em> and <em>b</em> paths are of the same sign, the proportion of the total effect that is mediated, <span class="math inline">\(\frac{me}{c}\)</span>, should also be reported. Because the Bayesian analysis automatically provides posterior distributions of these parameters, inference (and communication) should not focus on point estimates, but their associated uncertainty intervals should also be reported. Additionally, the communication and interpretation of mediation analyses is greatly facilitated by graphical descriptions of the data and estimated model, such as Figures @ref(fig:spaghetti-plot-binary-y) and @ref(fig:spaghetti-plot-b-binary-y). We have specifically designed <strong>bmlm</strong>’s plotting functions to facilitate the interpretation and communication of results.</p>
</div>
<div id="summary-of-bmlms-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#summary-of-bmlms-functions" class="anchor"></a>Summary of <strong>bmlm</strong>’s functions</h2>
<p>Above, we have illustrated the functionality of <strong>bmlm</strong> with an empirical example. Table @ref(tab:function-reference-table) provides a quick reference table to its main functions.</p>
<caption>
(#tab:function-reference-table)<em>Main functions of bmlm.</em>
</caption>
<table class="table">
<thead><tr class="header">
<th align="left">Function</th>
<th align="left">Purpose</th>
<th align="left">Inputs</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">isolate()</td>
<td align="left">Create within-person variables</td>
<td align="left">Data, variable names</td>
</tr>
<tr class="even">
<td align="left">mlm()</td>
<td align="left">Estimate a multilevel model</td>
<td align="left">Data, variable names, MCMC options</td>
</tr>
<tr class="odd">
<td align="left">mlm_summary()</td>
<td align="left">Print parameters to R console</td>
<td align="left">Model, parameters, credibility level</td>
</tr>
<tr class="even">
<td align="left">mlm_pars_plot()</td>
<td align="left">Plot mediation model’s parameters</td>
<td align="left">Model, plot type, parameters</td>
</tr>
<tr class="odd">
<td align="left">mlm_path_plot()</td>
<td align="left">Plot the model as a path diagram</td>
<td align="left">Model, variable names</td>
</tr>
<tr class="even">
<td align="left">mlm_spaghetti_plot()</td>
<td align="left">Plot fitted values (regression line)</td>
<td align="left">Model, data, variable names</td>
</tr>
<tr class="odd">
<td align="left">tab2doc()</td>
<td align="left">Create a Word summary document</td>
<td align="left">Results of mlm_summary()</td>
</tr>
</tbody>
</table>
<center>
<em>Note.</em> To learn more about each function, type the function’s name prepended with a question mark in the R console. This will bring out the function’s help page.
</center>
</div>
</div>
<div id="discussion" class="section level1">
<h1 class="hasAnchor">
<a href="#discussion" class="anchor"></a>Discussion</h1>
<div id="comparison-to-other-software" class="section level2">
<h2 class="hasAnchor">
<a href="#comparison-to-other-software" class="anchor"></a>Comparison to other software</h2>
<p>Software options for implementing multilevel mediation are limited, and to date have been limited to commercial software. Bolger &amp; Laurenceau <span class="citation">(2013)</span> used Mplus <span class="citation">(L. K. Muth’en &amp; Muth’en, 2017)</span> to estimate a 1 <span class="math inline">\(\rightarrow\)</span> 1 <span class="math inline">\(\rightarrow\)</span> 1 multilevel mediation with continuous Y, and here we provide a summary table comparing estimated parameters from <strong>bmlm</strong> and Mplus for the example discussed in Bolger &amp; Laurenceau <span class="citation">(2013)</span>. (This data set is included in <strong>bmlm</strong> as <code>BLch9</code>.)</p>
<caption>
(#tab:comparing-software-table)<em>Comparison of parameters estimated with bmlm and Mplus, from a model using example data presented in Bolger and Laurenceau (2013), chapter 9. The bmlm estimates are posterior means, and SEs are posterior standard deviations (based on 100,000 MCMC samples).</em>
</caption>
<table class="table">
<thead><tr class="header">
<th align="left">Parameter</th>
<th align="left">Estimate (bmlm)</th>
<th align="left">Estimate (Mplus)</th>
<th align="left">SE (bmlm)</th>
<th align="left">SE (Mplus)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">a</td>
<td align="left">0.19</td>
<td align="left">0.19</td>
<td align="left">0.04</td>
<td align="left">0.04</td>
</tr>
<tr class="even">
<td align="left">b</td>
<td align="left">0.15</td>
<td align="left">0.15</td>
<td align="left">0.03</td>
<td align="left">0.03</td>
</tr>
<tr class="odd">
<td align="left">cp</td>
<td align="left">0.10</td>
<td align="left">0.10</td>
<td align="left">0.02</td>
<td align="left">0.02</td>
</tr>
<tr class="even">
<td align="left">c</td>
<td align="left">0.16</td>
<td align="left">0.16</td>
<td align="left">0.03</td>
<td align="left">0.03</td>
</tr>
<tr class="odd">
<td align="left">me</td>
<td align="left">0.06</td>
<td align="left">0.06</td>
<td align="left">0.01</td>
<td align="left">0.01</td>
</tr>
<tr class="even">
<td align="left">pme</td>
<td align="left">0.36</td>
<td align="left">0.36</td>
<td align="left">0.08</td>
<td align="left">0.08</td>
</tr>
<tr class="odd">
<td align="left">covab</td>
<td align="left">0.03</td>
<td align="left">0.03</td>
<td align="left">0.01</td>
<td align="left">0.01</td>
</tr>
<tr class="even">
<td align="left">tau_a</td>
<td align="left">0.26</td>
<td align="left">0.26</td>
<td align="left">0.04</td>
<td align="left">NA</td>
</tr>
<tr class="odd">
<td align="left">tau_b</td>
<td align="left">0.22</td>
<td align="left">0.21</td>
<td align="left">0.03</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">tau_cp</td>
<td align="left">0.08</td>
<td align="left">0.09</td>
<td align="left">0.03</td>
<td align="left">NA</td>
</tr>
<tr class="odd">
<td align="left">sigma_y</td>
<td align="left">0.93</td>
<td align="left">0.92</td>
<td align="left">0.02</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">sigma_m</td>
<td align="left">1.09</td>
<td align="left">1.09</td>
<td align="left">0.02</td>
<td align="left">NA</td>
</tr>
</tbody>
</table>
<center>
<em>Note.</em> The variance components’ SEs are missing from the Mplus results because they were reported in the variance scale in Bolger and Laurenceau (2013), and therefore not directly comparable to the current results.
</center>
<p>Table @ref(tab:comparing-software-table) shows that the point estimates, and their standard errors (for <strong>bmlm</strong> these are posterior means and standard deviations), obtained from bmlm and Mplus are in agreement, and numerical differences are small. However, it is important to emphasize that only focusing on the point estimate and SE of some of the estimated parameters can be less informative than viewing the full posterior distribution, because the shape of the distribution can be very non-Gaussian, in which case these two numbers may be misleading. For example, Figure @ref(fig:example1-pop-hist) shows that the posterior distributions of standard deviation and covariance parameters characterizing the random effects may be very skewed; summarizing these with just a mean and SD may lead to inaccurate inferences. In summary, numerical results from <strong>bmlm</strong> are the same as would be obtained using commercial software (Mplus).</p>
<p>Why, then, should researchers choose to use <strong>bmlm</strong> over the more general Mplus software? First, on our reading, the Mplus software—and its modeling language—is not well known or commonly used within cognitive psychology and neuroscience. The R software, is well known within these fields, and because at its core <strong>bmlm</strong> is only a library of R functions, users who are familiar with R can estimate the model within minutes of installation. A second benefit of using the comparably more limited <strong>bmlm</strong> has to do with the fact that it is emphatically not a general purpose (structural equation) modeling tool; it does few things, but it does them well. For example, the figures illustrated above are very useful in interpreting and communicating results from the analysis, and are available to users by simply using their associated functions. Because Mplus is a general purpose modeling tool, it does not easily provide these types of figures for specific purposes, such as detailed here.</p>
<p>The two most important reasons for using <strong>bmlm</strong> over its commercial alternatives, such as Mplus, however, are openness and price. Regarding the former, there has recently been an enormous push toward increasing scientific reproducibility, openness, and transparency <span class="citation">(e.g. Eglen et al., 2017; Munaf‘o et al., 2017; Vuorre &amp; Curley, 2017)</span>. Because the source code of our program is freely available, it is easily accessible to public scrutiny, improvement and communication, thereby potentially increasing the aforementioned goals. Second, providing the package within the R ecosystem makes literate programming <span class="citation">(Knuth, 1984)</span> more accessible than standalone programs, thereby possibly improving reproducibility (literate programming is the combining of computer code and language to enhance technical communication). Finally, perhaps the most import difference between <strong>bmlm</strong> and its commercial alternatives, such as Mplus, is that our program and code is free to use, modify and extend. For many researchers, software licenses can be too expensive, but free programs don’t require re-allocation of research funds toward programs, and thereby make these useful methods available to a broader audience of researchers.</p>
</div>
<div id="limitations" class="section level2">
<h2 class="hasAnchor">
<a href="#limitations" class="anchor"></a>Limitations</h2>
<p>Currently, <strong>bmlm’s</strong> implementation of multilevel mediation requires that the data set be submitted to the analysis with complete rows. That is, missing cells within rows are not allowed, and users are required to either drop all rows of data that are not complete, or fill the data before entering it to the <code><a href="../../reference/mlm.html">mlm()</a></code> function. However, the software does not require that the data set is balanced either across individuals or across conditions within individuals. We believe that not allowing missing values is not a great limitation, because in cognitive experiments data is usually collected with a computerized experiment, making missing rows (e.g. outliers for M or Y leading to the entire trial being rejected from analysis; allowed) much more common than missing values (e.g. value for a single variable not logged for one trial; not allowed.)</p>
<p>Another limitation of <strong>bmlm</strong> is that it currently implements only the 1 <span class="math inline">\(\rightarrow\)</span> 1 <span class="math inline">\(\rightarrow\)</span> 1 mediation model (with continuous / binary Y), and more complex mediation models are not allowed. Furthermore, issues such as covariates and latent variables <span class="citation">(e.g. Cheong et al., 2003)</span> are often discussed in the literature on mediation, possibly making the model presented here seem as limited in scope. However, latent variables, longitudinal models, and covariates are not widely applicable in experimental studies in cognitive psychology and neuroscience: While future work might address these issues, we feel that this relatively simple model is widely (and easily) applicable to a wide range of data within these fields. Furthermore, the model’s Stan source code is extensively commented and modular, thus making it easier for experienced users to expand it to more complex models. We plan to implement some common but more complicated models in the software in our future work, but believe that the models currently provided cover a large number of common use cases in cognitive psychology and neuroscience.</p>
</div>
<div id="considerations-for-analyzing-causal-models" class="section level2">
<h2 class="hasAnchor">
<a href="#considerations-for-analyzing-causal-models" class="anchor"></a>Considerations for Analyzing Causal Models</h2>
<p>We also remind readers of the general limitations and pitfalls of analyzing causal models with statistical mediation, and the additional complications related to allowing the hypothesized causal effects to vary randomly between individuals. One of the primary benefits of controlled experiments is that hypothesized causal variables (X) are manipulated, and the causal assumptions are therefore easier to accept. With mediation models, the situation is more complicated because the mediating variable (M) is thought to exert a causal influence on Y, yet it is not experimentally manipulated.</p>
<p>Ultimately, to adjudicate causation from correlation in the M-Y relationship, strong theoretical, logical, and experimental considerations need to be taken into account. For instance, it is important to ensure that the temporal sequence of X, M, and Y within an experimental trial supports causation from M to Y and not vice versa. In the example presented above, we can fairly certainly assume that the actual game performance during a trial (hit rate) occurred and was determined before the subject’s judgment of performance (JoP) at the end of the trial. Another important consideration is that there should be no other mediator, correlated with the proposed M, that would instead explain the mediated effect.</p>
<p>A second issue with statistical mediation, and any regression method, is that measured variables are assumed to be measured without error. If M is a very noisy measure of the underlying construct, its association to M may be very difficult to find, or the relationship may be otherwise unrepresentative of the relationship between the actual construct that M represents and Y. Although outside the scope of this article, Bayesian methods allow relatively straightforward relaxation of this assumption: If researchers have information about the measurement error associated with a variable, they can include it in the model. This approach is used, for example, in the Bayesian regression R package brms <span class="citation">(Bürkner, 2017)</span>. Because M is measured, the assumption of no measurement error is often more difficult to satisfy in mediation models than in models where all predictors are experimentally manipulated.</p>
<p>Finally, the multilevel model allows all parameters to vary between subjects. It is therefore possible that while the population level estimated parameter might indicate a mediated effect for the average person, the subject-specific effects might indicate that the effect is very weak—or might be in the other direction—for a subset of individuals. In these cases, some researchers might object to the assertion that the mediation effect holds in the population. However, we think that significant between-subject variance is a source of inspiration for future research. We also note that the important issue of between-person heterogeneity is not specific to multilevel mediation, but applies to all research and analyses where effects can vary between individuals. Multilevel models are useful–among other reasons–because they bring this heterogeneity to researchers’ attention, and possibly deepen their understanding of the research question.</p>
</div>
<div id="software-dependencies-and-development" class="section level2">
<h2 class="hasAnchor">
<a href="#software-dependencies-and-development" class="anchor"></a>Software dependencies and development</h2>
<p>At its core, <strong>bmlm</strong> uses the Stan programming language through the rstan R interface for estimating the mediation model <span class="citation">(Stan Development Team, 2016a, 2016b)</span>. After estimating the model, users may export the underlying Stan code (run <code>cat(rstan::get_stancode(fit))</code> in R) and use it to extend the mediation model to answer more complex questions. <strong>bmlm</strong>’s core functions also depend on the R packages dplyr <span class="citation">(Wickham &amp; Francois, 2016)</span> and Rcpp <span class="citation">(Eddelbuettel &amp; Francois, 2011)</span>. <strong>bmlm</strong>’s plotting functions depend on R packages ggplot2 <span class="citation">(Wickham, 2016)</span> and qgraph <span class="citation">(Epskamp, Cramer, Waldorp, Schmittmann, &amp; Borsboom, 2012)</span>. Situating <strong>bmlm</strong> in the R ecosystem also makes it easy for users to write reproducible reports and manuscripts using the R packages knitr <span class="citation">(Xie et al., 2016)</span>, R Markdown <span class="citation">(Allaire et al., 2016)</span>, and papaja <span class="citation">(Aust &amp; Barth, 2016)</span>. Users may also use the <code><a href="../../reference/tab2doc.html">tab2doc()</a></code> function to directly export <strong>bmlm</strong>’s results to a Word table <span class="citation">(Gohel, 2016)</span>.</p>
<p>For more extensive user instructions, we direct users to the package’s website<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. For comments and feedback, such as suggestions of new features, users may visit the package’s GitHub website and leave a request for a new feature. This website also allows more advanced users to copy the package’s source code for extending its functionality.</p>
</div>
<div id="conclusion" class="section level2">
<h2 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h2>
<p>Statistical mediation allows researchers to address questions about causal mechanisms in which the effect of one variable on another is mediated by a third variable. Such research questions about causal relations are commonplace and important in psychological science, but to date have most commonly concerned between-person causal relations. The analysis of mediation at the within-person level is relatively uncommon and presents additional complexities, but comes with great benefits: When individual participants provide multiple measures of the IV, DV, and mediating variable, mediation can be assessed for each individual and the population average, and the inference to within-person psychological processes is more straightforward. Additionally, multilevel mediation analysis provides estimates of the between-person variability (heterogeneity) in the effects, which are important when considering the generalizability of the observed effects <span class="citation">(Bolger &amp; Laurenceau, 2013)</span>.</p>
<p>Here, we discussed the multilevel modeling approach to investigating within-person mediation <span class="citation">(Kenny et al., 1998, 2003)</span>, and introduced a free, open-source software package for the R programming environment for conducting Bayesian multilevel mediation analyses <span class="citation">(<strong>bmlm</strong>; Vuorre, 2016)</span>. This software package allows users to easily estimate multilevel mediation models, and summarize and visualize its results. The software package is freely available at <a href="https://cran.r-project.org/package=bmlm" class="uri">https://cran.r-project.org/package=bmlm</a>.</p>
</div>
</div>
<div id="acknowledgements" class="section level1">
<h1 class="hasAnchor">
<a href="#acknowledgements" class="anchor"></a>Acknowledgements</h1>
<p>We would like to thank Janet Metcalfe, Teal Eich, and Alan Castel for making their data available. We also acknowledge Ben Goodrich and Jonah Gabry’s help with the development of bmlm on GitHub. This research was supported, in part, by Institute of Education Science grant (R305A150467). The authors are solely responsible for the content of this article.</p>

</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-allaire_rmarkdown:_2016">
<p>Allaire, J. J., Cheng, J., Xie, Y., McPherson, J., Chang, W., Allen, J., … (Ionicons), D. (2016). Rmarkdown: Dynamic Documents for R (Version 1.3). Retrieved from <a href="https://cran.r-project.org/web/packages/rmarkdown/index.html" class="uri">https://cran.r-project.org/web/packages/rmarkdown/index.html</a></p>
</div>
<div id="ref-atlas_brain_2010">
<p>Atlas, L. Y., Bolger, N., Lindquist, M. A., &amp; Wager, T. D. (2010). Brain mediators of predictive cue effects on perceived pain. <em>The Journal of Neuroscience</em>, <em>30</em>(39), 12964–12977. <a href="http://doi.org/10.1523/JNEUROSCI.0057-10.2010" class="uri">http://doi.org/10.1523/JNEUROSCI.0057-10.2010</a></p>
</div>
<div id="ref-aust_papaja:_2016">
<p>Aust, F., &amp; Barth, M. (2016). <em>Papaja: Create APA manuscripts with RMarkdown</em>. Retrieved from <a href="https://github.com/crsh/papaja" class="uri">https://github.com/crsh/papaja</a></p>
</div>
<div id="ref-baguley_standardized_2009">
<p>Baguley, T. (2009). Standardized or simple effect size: What should be reported? <em>British Journal of Psychology</em>, <em>100</em>(3), 603–617. <a href="http://doi.org/10.1348/000712608X377117" class="uri">http://doi.org/10.1348/000712608X377117</a></p>
</div>
<div id="ref-baron_moderatormediator_1986">
<p>Baron, R. M., &amp; Kenny, D. A. (1986). The moderator–mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations. <em>Journal of Personality and Social Psychology</em>, <em>51</em>(6), 1173–1182. <a href="http://doi.org/10.1037/0022-3514.51.6.1173" class="uri">http://doi.org/10.1037/0022-3514.51.6.1173</a></p>
</div>
<div id="ref-bauer_conceptualizing_2006">
<p>Bauer, D. J., Preacher, K. J., &amp; Gil, K. M. (2006). Conceptualizing and testing random indirect effects and moderated mediation in multilevel models: New procedures and recommendations. <em>Psychological Methods</em>, <em>11</em>(2), 142–163. <a href="http://doi.org/10.1037/1082-989X.11.2.142" class="uri">http://doi.org/10.1037/1082-989X.11.2.142</a></p>
</div>
<div id="ref-bolger_intensive_2013">
<p>Bolger, N., &amp; Laurenceau, J.-P. (2013). <em>Intensive longitudinal methods: An introduction to diary and experience sampling research</em>. Guilford Press. Retrieved from <a href="http://www.intensivelongitudinal.com/" class="uri">http://www.intensivelongitudinal.com/</a></p>
</div>
<div id="ref-burkner_brms:_2017">
<p>Bürkner, P.-C. (2017). Brms: An R Package for Bayesian Multilevel Models Using Stan. <em>Journal of Statistical Software</em>, <em>80</em>(1), 1–28. <a href="http://doi.org/10.18637/jss.v080.i01" class="uri">http://doi.org/10.18637/jss.v080.i01</a></p>
</div>
<div id="ref-cheong_investigation_2003">
<p>Cheong, J., MacKinnon, D. P., &amp; Khoo, S. T. (2003). Investigation of Mediational Processes Using Parallel Process Latent Growth Curve Modeling. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>10</em>(2), 238–262. <a href="http://doi.org/10.1207/S15328007SEM1002_5" class="uri">http://doi.org/10.1207/S15328007SEM1002_5</a></p>
</div>
<div id="ref-cole_testing_2003">
<p>Cole, D. A., &amp; Maxwell, S. E. (2003). Testing Mediational Models With Longitudinal Data: Questions and Tips in the Use of Structural Equation Modeling. <em>Journal of Abnormal Psychology</em>, <em>112</em>(4), 558–577. <a href="http://doi.org/10.1037/0021-843X.112.4.558" class="uri">http://doi.org/10.1037/0021-843X.112.4.558</a></p>
</div>
<div id="ref-JSSv040i08">
<p>Eddelbuettel, D., &amp; Francois, R. (2011). Rcpp: Seamless R and C++ Integration. <em>Journal of Statistical Software</em>, <em>40</em>(1), 1–18. <a href="http://doi.org/10.18637/jss.v040.i08" class="uri">http://doi.org/10.18637/jss.v040.i08</a></p>
</div>
<div id="ref-eglen_toward_2017">
<p>Eglen, S. J., Marwick, B., Halchenko, Y. O., Hanke, M., Sufi, S., Gleeson, P., … Poline, J.-B. (2017). Toward standard practices for sharing computer code and programs in neuroscience. <em>Nature Neuroscience</em>, <em>20</em>(6), 770–773. <a href="http://doi.org/10.1038/nn.4550" class="uri">http://doi.org/10.1038/nn.4550</a></p>
</div>
<div id="ref-epskamp_qgraph:_2012">
<p>Epskamp, S., Cramer, A. O. J., Waldorp, L. J., Schmittmann, V. D., &amp; Borsboom, D. (2012). Qgraph: Network Visualizations of Relationships in Psychometric Data. <em>Journal of Statistical Software</em>, <em>48</em>(4), 1–18. Retrieved from <a href="http://www.jstatsoft.org/v48/i04/" class="uri">http://www.jstatsoft.org/v48/i04/</a></p>
</div>
<div id="ref-gelman_prior_2006">
<p>Gelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by browne and draper). <em>Bayesian Analysis</em>, <em>1</em>(3), 515–534. Retrieved from <a href="http://projecteuclid.org/euclid.ba/1340371048" class="uri">http://projecteuclid.org/euclid.ba/1340371048</a></p>
</div>
<div id="ref-gelman_data_2007">
<p>Gelman, A., &amp; Hill, J. (2007). <em>Data analysis using regression and multilevel/hierarchical models</em>. Cambridge University Press.</p>
</div>
<div id="ref-gelman_bayesian_2013">
<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). <em>Bayesian data analysis, third edition</em>. Boca Raton: Chapman; Hall/CRC.</p>
</div>
<div id="ref-gohel_reporters:_2016-1">
<p>Gohel, D. (2016). <em>ReporteRs: Microsoft Word and PowerPoint Documents Generation</em>. Retrieved from <a href="https://CRAN.R-project.org/package=ReporteRs" class="uri">https://CRAN.R-project.org/package=ReporteRs</a></p>
</div>
<div id="ref-hoffman_no-u-turn_2014">
<p>Hoffman, M. D., &amp; Gelman, A. (2014). The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo. <em>Journal of Machine Learning Research</em>, <em>15</em>(1), 1593–1623.</p>
</div>
<div id="ref-ishigami_is_2009">
<p>Ishigami, Y., &amp; Klein, R. M. (2009). Is a hands-free phone safer than a handheld phone? <em>Journal of Safety Research</em>, <em>40</em>(2), 157–164. <a href="http://doi.org/10.1016/j.jsr.2009.02.006" class="uri">http://doi.org/10.1016/j.jsr.2009.02.006</a></p>
</div>
<div id="ref-judd_estimating_2001">
<p>Judd, C. M., Kenny, D. A., &amp; McClelland, G. H. (2001). Estimating and testing mediation and moderation in within-subject designs. <em>Psychological Methods</em>, <em>6</em>(2), 115–134. <a href="http://doi.org/10.1037/1082-989X.6.2.115" class="uri">http://doi.org/10.1037/1082-989X.6.2.115</a></p>
</div>
<div id="ref-kass_bayes_1995">
<p>Kass, R. E., &amp; Raftery, A. E. (1995). Bayes Factors. <em>Journal of the American Statistical Association</em>, <em>90</em>(430), 773–795. <a href="http://doi.org/10.1080/01621459.1995.10476572" class="uri">http://doi.org/10.1080/01621459.1995.10476572</a></p>
</div>
<div id="ref-kenny_data_1998">
<p>Kenny, D. A., Kashy, D. A., &amp; Bolger, N. (1998). Data analysis in social psychology. In D. T. Gilbert, S. T. Fiske, &amp; G. Lindzey (Eds.), <em>The handbook of social psychology, vols. 1 and 2 (4th ed.)</em> (pp. 233–265). New York, NY, US: McGraw-Hill.</p>
</div>
<div id="ref-kenny_lower_2003">
<p>Kenny, D. A., Korchmaros, J. D., &amp; Bolger, N. (2003). Lower level mediation in multilevel models. <em>Psychological Methods</em>, <em>8</em>(2), 115–128. <a href="http://doi.org/10.1037/1082-989X.8.2.115" class="uri">http://doi.org/10.1037/1082-989X.8.2.115</a></p>
</div>
<div id="ref-knuth_literate_1984">
<p>Knuth, D. E. (1984). Literate Programming. <em>The Computer Journal</em>, <em>27</em>(2), 97–111. <a href="http://doi.org/10.1093/comjnl/27.2.97" class="uri">http://doi.org/10.1093/comjnl/27.2.97</a></p>
</div>
<div id="ref-krull_multilevel_2001">
<p>Krull, J. L., &amp; MacKinnon, D. P. (2001). Multilevel modeling of individual and group level mediated effects. <em>Multivariate Behavioral Research</em>, <em>36</em>(2), 249–277. <a href="http://doi.org/10.1207/S15327906MBR3602_06" class="uri">http://doi.org/10.1207/S15327906MBR3602_06</a></p>
</div>
<div id="ref-kruschke_doing_2014">
<p>Kruschke, J. K. (2014). <em>Doing bayesian data analysis: A tutorial introduction with r</em> (2nd Edition). Burlington, MA: Academic Press.</p>
</div>
<div id="ref-lewandowski_generating_2009">
<p>Lewandowski, D., Kurowicka, D., &amp; Joe, H. (2009). Generating random correlation matrices based on vines and extended onion method. <em>Journal of Multivariate Analysis</em>, <em>100</em>(9), 1989–2001. <a href="http://doi.org/10.1016/j.jmva.2009.04.008" class="uri">http://doi.org/10.1016/j.jmva.2009.04.008</a></p>
</div>
<div id="ref-mackinnon_introduction_2008">
<p>MacKinnon, D. P. (2008). <em>Introduction to Statistical Mediation Analysis</em>. Routledge.</p>
</div>
<div id="ref-mackinnon_estimating_1993">
<p>MacKinnon, D. P., &amp; Dwyer, J. H. (1993). Estimating Mediated Effects in Prevention Studies. <em>Evaluation Review</em>, <em>17</em>(2), 144–158. <a href="http://doi.org/10.1177/0193841X9301700202" class="uri">http://doi.org/10.1177/0193841X9301700202</a></p>
</div>
<div id="ref-mackinnon_mediation_2007">
<p>MacKinnon, D. P., Fairchild, A. J., &amp; Fritz, M. S. (2007). Mediation analysis. <em>Annual Review of Psychology</em>, <em>58</em>(1), 593–614. <a href="http://doi.org/10.1146/annurev.psych.58.110405.085542" class="uri">http://doi.org/10.1146/annurev.psych.58.110405.085542</a></p>
</div>
<div id="ref-mackinnon_simulation_1995">
<p>MacKinnon, D. P., Warsi, G., &amp; Dwyer, J. H. (1995). A simulation study of mediated effect measures. <em>Multivariate Behavioral Research</em>, <em>30</em>(1), 41–62. <a href="http://doi.org/10.1207/s15327906mbr3001_3" class="uri">http://doi.org/10.1207/s15327906mbr3001_3</a></p>
</div>
<div id="ref-marsman_three_2016">
<p>Marsman, M., &amp; Wagenmakers, E.-J. (2016). Three Insights from a Bayesian Interpretation of the One-Sided P Value. <em>Educational and Psychological Measurement</em>. <a href="http://doi.org/10.1177/0013164416669201" class="uri">http://doi.org/10.1177/0013164416669201</a></p>
</div>
<div id="ref-mcelreath_statistical_2016">
<p>McElreath, R. (2016). <em>Statistical rethinking: A bayesian course with examples in r and stan</em>. CRC Press.</p>
</div>
<div id="ref-metcalfe_metacognition_2007">
<p>Metcalfe, J., &amp; Greene, M. J. (2007). Metacognition of agency. <em>Journal of Experimental Psychology: General</em>, <em>136</em>(2), 184–199. <a href="http://doi.org/10.1037/0096-3445.136.2.184" class="uri">http://doi.org/10.1037/0096-3445.136.2.184</a></p>
</div>
<div id="ref-metcalfe_metacognition_2010">
<p>Metcalfe, J., Eich, T. S., &amp; Castel, A. D. (2010). Metacognition of agency across the lifespan. <em>Cognition</em>, <em>116</em>(2), 267–282. <a href="http://doi.org/10.1016/j.cognition.2010.05.009" class="uri">http://doi.org/10.1016/j.cognition.2010.05.009</a></p>
</div>
<div id="ref-montoya_two-condition_2017">
<p>Montoya, A. K., &amp; Hayes, A. F. (2017). Two-condition within-participant statistical mediation analysis: A path-analytic framework. <em>Psychological Methods</em>, <em>22</em>(1), 6. <a href="http://doi.org/10.1037/met0000086" class="uri">http://doi.org/10.1037/met0000086</a></p>
</div>
<div id="ref-morey_fallacy_2015">
<p>Morey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., &amp; Wagenmakers, E.-J. (2015). The fallacy of placing confidence in confidence intervals. <em>Psychonomic Bulletin &amp; Review</em>.</p>
</div>
<div id="ref-munafo_manifesto_2017">
<p>Munaf‘o, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., du Sert, N. P., … Ioannidis, J. P. A. (2017). A manifesto for reproducible science. <em>Nature Human Behaviour</em>, <em>1</em>, 0021. <a href="http://doi.org/10.1038/s41562-016-0021" class="uri">http://doi.org/10.1038/s41562-016-0021</a></p>
</div>
<div id="ref-muthen_mplus_2017">
<p>Muth’en, L. K., &amp; Muth’en, B. O. (2017). <em>Mplus User’s Guide</em> (8th ed.). Los Angeles, CA: Muthén &amp; Muthén.</p>
</div>
<div id="ref-preacher_advances_2015">
<p>Preacher, K. J. (2015). Advances in mediation analysis: A survey and synthesis of new developments. <em>Annual Review of Psychology</em>, <em>66</em>(1), 825–852. <a href="http://doi.org/10.1146/annurev-psych-010814-015258" class="uri">http://doi.org/10.1146/annurev-psych-010814-015258</a></p>
</div>
<div id="ref-preacher_effect_2011">
<p>Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: Quantitative strategies for communicating indirect effects. <em>Psychological Methods</em>, <em>16</em>(2), 93–115. <a href="http://doi.org/10.1037/a0022658" class="uri">http://doi.org/10.1037/a0022658</a></p>
</div>
<div id="ref-preacher_general_2010">
<p>Preacher, K. J., Zyphur, M. J., &amp; Zhang, Z. (2010). A general multilevel SEM framework for assessing multilevel mediation. <em>Psychological Methods</em>, <em>15</em>(3), 209–233. <a href="http://doi.org/10.1037/a0020141" class="uri">http://doi.org/10.1037/a0020141</a></p>
</div>
<div id="ref-r_core_team_r:_2016">
<p>R Core Team. (2016). <em>R: A language and environment for statistical computing</em>. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a></p>
</div>
<div id="ref-raudenbush_assessing_1999">
<p>Raudenbush, S. W., &amp; Sampson, R. (1999). Assessing Direct and Indirect Effects in Multilevel Designs with Latent Variables. <em>Sociological Methods &amp; Research</em>, <em>28</em>(2), 123–153. <a href="http://doi.org/10.1177/0049124199028002001" class="uri">http://doi.org/10.1177/0049124199028002001</a></p>
</div>
<div id="ref-rouder_is_2016">
<p>Rouder, J. N., Morey, R. D., Verhagen, J., Province, J. M., &amp; Wagenmakers, E.-J. (2016). Is There a Free Lunch in Inference? <em>Topics in Cognitive Science</em>, <em>8</em>(3), 520–547. <a href="http://doi.org/10.1111/tops.12214" class="uri">http://doi.org/10.1111/tops.12214</a></p>
</div>
<div id="ref-selig_mediation_2009">
<p>Selig, J. P., &amp; Preacher, K. J. (2009). Mediation Models for Longitudinal Data in Developmental Research. <em>Research in Human Development</em>, <em>6</em>(2-3), 144–164. <a href="http://doi.org/10.1080/15427600902911247" class="uri">http://doi.org/10.1080/15427600902911247</a></p>
</div>
<div id="ref-shrout_mediation_2002">
<p>Shrout, P. E., &amp; Bolger, N. (2002). Mediation in experimental and nonexperimental studies: New procedures and recommendations. <em>Psychological Methods</em>, <em>7</em>(4), 422–445. <a href="http://doi.org/10.1037/1082-989X.7.4.422" class="uri">http://doi.org/10.1037/1082-989X.7.4.422</a></p>
</div>
<div id="ref-stan_development_team_rstan:_2016">
<p>Stan Development Team. (2016a). <em>RStan: The R interface to Stan</em>. Retrieved from <a href="http://mc-stan.org/" class="uri">http://mc-stan.org/</a></p>
</div>
<div id="ref-stan_development_team_stan:_2016">
<p>Stan Development Team. (2016b). <em>Stan: A C++ Library for Probability and Sampling, Version 2.14.1</em>. Retrieved from <a href="http://mc-stan.org/" class="uri">http://mc-stan.org/</a></p>
</div>
<div id="ref-stroop_studies_1935">
<p>Stroop, J. R. (1935). Studies of interference in serial verbal reactions. <em>Journal of Experimental Psychology</em>, <em>18</em>(6), 643–662. <a href="http://doi.org/10.1037/h0054651" class="uri">http://doi.org/10.1037/h0054651</a></p>
</div>
<div id="ref-tofighi_multilevel_2013">
<p>Tofighi, D., West, S. G., &amp; MacKinnon, D. P. (2013). Multilevel mediation analysis: The effects of omitted variables in the 1–1–1 model. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>66</em>(2), 290–307. <a href="http://doi.org/10.1111/j.2044-8317.2012.02051.x" class="uri">http://doi.org/10.1111/j.2044-8317.2012.02051.x</a></p>
</div>
<div id="ref-tukey_analyzing_1969">
<p>Tukey, J. W. (1969). Analyzing data: Sanctification or detective work? <em>American Psychologist</em>, <em>24</em>(2), 83–91. <a href="http://doi.org/10.1037/h0027108" class="uri">http://doi.org/10.1037/h0027108</a></p>
</div>
<div id="ref-valente_comparing_2017">
<p>Valente, M. J., &amp; MacKinnon, D. P. (2017). Comparing Models of Change to Estimate the Mediated Effect in the Pretest–Posttest Control Group Design. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>24</em>(3), 428–450. <a href="http://doi.org/10.1080/10705511.2016.1274657" class="uri">http://doi.org/10.1080/10705511.2016.1274657</a></p>
</div>
<div id="ref-ravenzwaaij_simple_2016">
<p>van Ravenzwaaij, D., Cassey, P., &amp; Brown, S. D. (2016). A simple introduction to Markov Chain Monte–Carlo sampling. <em>Psychonomic Bulletin &amp; Review</em>, 1–12. <a href="http://doi.org/10.3758/s13423-016-1015-8" class="uri">http://doi.org/10.3758/s13423-016-1015-8</a></p>
</div>
<div id="ref-vuorre_bmlm:_2016">
<p>Vuorre, M. (2016). <em>Bmlm: Bayesian Multilevel Mediation</em>. Retrieved from <a href="https://cran.r-project.org/package=bmlm" class="uri">https://cran.r-project.org/package=bmlm</a></p>
</div>
<div id="ref-vuorre_curating_2017">
<p>Vuorre, M., &amp; Curley, J. P. (2017). Curating Research Assets in Behavioral Sciences: A Tutorial on the Git Version Control System. <em>PsyArXiv Preprints</em>. <a href="http://doi.org/10.17605/OSF.IO/TXGN8" class="uri">http://doi.org/10.17605/OSF.IO/TXGN8</a></p>
</div>
<div id="ref-vuorre_relation_2016">
<p>Vuorre, M., &amp; Metcalfe, J. (2016). The relation between the sense of agency and the experience of flow. <em>Consciousness and Cognition</em>, <em>43</em>, 133–142. <a href="http://doi.org/10.1016/j.concog.2016.06.001" class="uri">http://doi.org/10.1016/j.concog.2016.06.001</a></p>
</div>
<div id="ref-wagenmakers_bayesian_2010">
<p>Wagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., &amp; Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. <em>Cognitive Psychology</em>, <em>60</em>(3), 158–189. <a href="http://doi.org/10.1016/j.cogpsych.2009.12.001" class="uri">http://doi.org/10.1016/j.cogpsych.2009.12.001</a></p>
</div>
<div id="ref-wang_moderated_2015">
<p>Wang, L. (Peggy), &amp; Preacher, K. J. (2015). Moderated Mediation Analysis Using Bayesian Methods. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>22</em>(2), 249–263. <a href="http://doi.org/10.1080/10705511.2014.935256" class="uri">http://doi.org/10.1080/10705511.2014.935256</a></p>
</div>
<div id="ref-wen_monotonicity_2015">
<p>Wen, Z., &amp; Fan, X. (2015). Monotonicity of effect sizes: Questioning kappa-squared as mediation effect size measure. <em>Psychological Methods</em>, <em>20</em>(2), 193–203. <a href="http://doi.org/10.1037/met0000029" class="uri">http://doi.org/10.1037/met0000029</a></p>
</div>
<div id="ref-wickham_ggplot2:_2016">
<p>Wickham, H. (2016). <em>Ggplot2: Elegant Graphics for Data Analysis</em> (2nd ed.). Springer Science &amp; Business Media.</p>
</div>
<div id="ref-wickham_dplyr:_2016">
<p>Wickham, H., &amp; Francois, R. (2016). <em>Dplyr: A Grammar of Data Manipulation</em>. Retrieved from <a href="http://CRAN.R-project.org/package=dplyr" class="uri">http://CRAN.R-project.org/package=dplyr</a></p>
</div>
<div id="ref-winship_structural_1983">
<p>Winship, C., &amp; Mare, R. D. (1983). Structural Equations and Path Analysis for Discrete Data. <em>American Journal of Sociology</em>, <em>89</em>(1), 54–110. <a href="http://doi.org/10.1086/227834" class="uri">http://doi.org/10.1086/227834</a></p>
</div>
<div id="ref-xie_knitr:_2016">
<p>Xie, Y., Vogt, A., Andrew, A., Zvoleff, A., Simon, A., Atkins, A., … Foster, Z. (2016). Knitr: A General-Purpose Package for Dynamic Report Generation in R (Version 1.15.1). Retrieved from <a href="https://cran.r-project.org/web/packages/knitr/index.html" class="uri">https://cran.r-project.org/web/packages/knitr/index.html</a></p>
</div>
<div id="ref-yuan_bayesian_2009">
<p>Yuan, Y., &amp; MacKinnon, D. P. (2009). Bayesian mediation analysis. <em>Psychological Methods</em>, <em>14</em>(4), 301–322. <a href="http://doi.org/10.1037/a0016972" class="uri">http://doi.org/10.1037/a0016972</a></p>
</div>
<div id="ref-zhang_testing_2009">
<p>Zhang, Z., Zyphur, M. J., &amp; Preacher, K. J. (2009). Testing multilevel mediation using hierarchical linear models problems and solutions. <em>Organizational Research Methods</em>, <em>12</em>(4), 695–719. <a href="http://doi.org/10.1177/1094428108327450" class="uri">http://doi.org/10.1177/1094428108327450</a></p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>We refer to the subject-level parameters as effects, although they more accurately represent deviations of the subject-level parameters from the population-level average effects. We use this nomenclature for two reasons: First, we believe it is more straightforward and avoids an unimportant technicality. Second, although we could have directly written the model so that the subject-level parameters are effects, not deviations from the population-level effects, we found that the MCMC algorithms were more efficient when using the parameterization presented here. Importantly, the subject-specific effects returned by the software (such as those Figure @ref(fig:example1-subj-coefs)) are not deviations from the average effect, but instead have the average effect added to them and can therefore be considered as the subject-specific effects.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="http://mc-stan.org/" class="uri">http://mc-stan.org/</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="https://mvuorre.github.io/bmlm/" class="uri">https://mvuorre.github.io/bmlm/</a>.<a href="#fnref3">↩</a></p></li>
</ol>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#abstract">Abstract</a></li>
      <li>
<a href="#introduction">Introduction</a><ul class="nav nav-pills nav-stacked">
<li><a href="#mediation">Mediation</a></li>
      <li><a href="#multilevel-mediation-model-for-repeated-measures">Multilevel mediation model for repeated measures</a></li>
      <li><a href="#alternatives-to-multilevel-models">Alternatives to multilevel models</a></li>
      <li><a href="#bayesian-estimation">Bayesian estimation</a></li>
      </ul>
</li>
      <li>
<a href="#software-package-for-bayesian-multilevel-mediation-bmlm">Software package for Bayesian multilevel mediation: bmlm</a><ul class="nav nav-pills nav-stacked">
<li><a href="#example-judgments-of-performance-in-a-video-game-task">Example: Judgments of performance in a video game task</a></li>
      <li><a href="#data-set">Data set</a></li>
      <li><a href="#estimating-the-multilevel-mediation-model-with-bmlm">Estimating the multilevel mediation model with bmlm</a></li>
      <li><a href="#summarizing-the-multilevel-mediation-model">Summarizing the multilevel mediation model</a></li>
      <li><a href="#visualizing-the-estimated-parameters">Visualizing the estimated parameters</a></li>
      <li><a href="#mediation-with-binary-outcomes">Mediation with binary outcomes</a></li>
      <li><a href="#visualizing-the-models-fitted-values">Visualizing the model’s fitted values</a></li>
      <li><a href="#estimating-the-magnitude-of-mediation">Estimating the magnitude of mediation</a></li>
      <li><a href="#summary-of-bmlms-functions">Summary of <strong>bmlm</strong>’s functions</a></li>
      </ul>
</li>
      <li>
<a href="#discussion">Discussion</a><ul class="nav nav-pills nav-stacked">
<li><a href="#comparison-to-other-software">Comparison to other software</a></li>
      <li><a href="#limitations">Limitations</a></li>
      <li><a href="#considerations-for-analyzing-causal-models">Considerations for Analyzing Causal Models</a></li>
      <li><a href="#software-dependencies-and-development">Software dependencies and development</a></li>
      <li><a href="#conclusion">Conclusion</a></li>
      </ul>
</li>
      <li><a href="#acknowledgements">Acknowledgements</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Matti Vuorre.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
